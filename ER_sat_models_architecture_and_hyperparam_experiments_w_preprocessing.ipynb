{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "architecture_and_hyperparam_experiments_w_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/ER_sat_models_architecture_and_hyperparam_experiments_w_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHeoGlIX2sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"emilySaturdayNight\"\n",
        "\n",
        "hyp_combos = [  \n",
        "                {'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 2,\n",
        "                'CONV_LAYER_SIZE': 256,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},  \n",
        "               {'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 2,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "               {'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 4,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "               {'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 256,\n",
        "                'FILTER_SIZES': [3, 4, 5],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "              {'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 256,\n",
        "                'FILTER_SIZES': [3, 4, 5],\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "             \n",
        "               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh1bBq9Vw_8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "756a5e14-cc79-4e91-fc13-9944469d8cd7"
      },
      "source": [
        " {'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'BYO',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZES': [128, 128],\n",
              "  'DROPOUT_RATES': [0.2, 0.2],\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [4, 4],\n",
              "  'FINAL_DENSE_LAYER_SIZE': 10,\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 1,\n",
              "  'NUM_LAYERS': 2,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "88eb280f-2d34-44aa-b4d7-e9393dc71f98"
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n",
            "Model 1 passed\n",
            "Model 2 passed\n",
            "Model 3 passed\n",
            "Model 4 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "outputId": "b679a977-073b-471c-9954-0c3a5a1a1433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "outputId": "2a9b9220-94de-4af7-e3fb-3815ca4223f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "- [4 files][  2.1 GiB/  2.1 GiB]  146.2 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "\\ [5 files][  2.9 GiB/  2.9 GiB]  164.2 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(1)\n",
        "        else:\n",
        "            final_list.append(0)\n",
        "    male = sum(final_list)\n",
        "    female = len(final_list)-sum(final_list)\n",
        "    percent_male = sum(final_list)/len(final_list)\n",
        "    print('total M: {}, total W: {}, percent M: {}'.format(male,female,percent_male))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(1)\n",
        "        else:\n",
        "            final_list.append(0)\n",
        "    republican = sum(final_list)\n",
        "    not_repub = len(final_list)-sum(final_list)\n",
        "    percent_repub = sum(final_list)/len(final_list)\n",
        "    print('total republican: {}, total not republican: {}, percent republican: {}'.format(republican,not_repub,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'M'\n",
        "  else:\n",
        "    return 'W'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Republican'\n",
        "  else:\n",
        "    return 'Not_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(.5)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "outputId": "471da0a6-77e8-43c4-bf48-7ca2d1ddbe07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Republican' in dev_df.preds2.value_counts():\n",
        "    proportion_republican_predicted = dev_df.preds2.value_counts()['Congress_Republican'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_republican_predicted = 0\n",
        "  print(\"Proportion of predictions for Republican class: {}\".format(proportion_republican_predicted))\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755718 training rows\n",
            "Responses include only the first 10 and last 10 words\n",
            "Getting labels\n",
            "training set:\n",
            "total M: 2751562, total W: 1004156, percent M: 0.7326327482521319\n",
            "dev set:\n",
            "total M: 1821965, total W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "total republican: 2336882, total not republican: 1402523, percent republican: 0.6249341807052191\n",
            "dev set:\n",
            "total republican: 1593280, total not republican: 557512, percent republican: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 10 seconds\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 50)            250150    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 20, 256)           38656     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 20, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 9, 256)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 9, 256)            196864    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 9, 256)            196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 879,655\n",
            "Trainable params: 629,505\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3755718 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3755718/3755718 [==============================] - 109s 29us/step - loss: 0.5191 - acc: 0.7653 - val_loss: 0.4190 - val_acc: 0.8480\n",
            "Epoch 2/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.5005 - acc: 0.7744 - val_loss: 0.4241 - val_acc: 0.8470\n",
            "Epoch 3/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.4947 - acc: 0.7771 - val_loss: 0.4250 - val_acc: 0.8468\n",
            "Epoch 4/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.4917 - acc: 0.7786 - val_loss: 0.4221 - val_acc: 0.8461\n",
            "Epoch 5/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.4894 - acc: 0.7793 - val_loss: 0.4413 - val_acc: 0.8406\n",
            "Epoch 6/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.4877 - acc: 0.7802 - val_loss: 0.4200 - val_acc: 0.8453\n",
            "Epoch 7/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.4865 - acc: 0.7807 - val_loss: 0.4365 - val_acc: 0.8406\n",
            "Epoch 8/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.4852 - acc: 0.7813 - val_loss: 0.4271 - val_acc: 0.8455\n",
            "Epoch 9/10\n",
            "3755718/3755718 [==============================] - 106s 28us/step - loss: 0.4842 - acc: 0.7816 - val_loss: 0.4254 - val_acc: 0.8459\n",
            "Epoch 10/10\n",
            "3755718/3755718 [==============================] - 105s 28us/step - loss: 0.4835 - acc: 0.7821 - val_loss: 0.4360 - val_acc: 0.8455\n",
            "Trained in 17 minutes, 35 seconds\n",
            "Copying file:///content/emilySaturdayNight_model_0_gender_1574571887.0150244.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/8.2 MiB.                                      \n",
            "Proportion of predictions for W class: 0.03912326250051144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739405 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3739405/3739405 [==============================] - 105s 28us/step - loss: 0.6097 - acc: 0.6619 - val_loss: 0.5777 - val_acc: 0.7298\n",
            "Epoch 2/10\n",
            "3739405/3739405 [==============================] - 105s 28us/step - loss: 0.5830 - acc: 0.6804 - val_loss: 0.5739 - val_acc: 0.7322\n",
            "Epoch 3/10\n",
            "3739405/3739405 [==============================] - 104s 28us/step - loss: 0.5737 - acc: 0.6866 - val_loss: 0.5641 - val_acc: 0.7386\n",
            "Epoch 4/10\n",
            "3739405/3739405 [==============================] - 104s 28us/step - loss: 0.5681 - acc: 0.6901 - val_loss: 0.5606 - val_acc: 0.7372\n",
            "Epoch 5/10\n",
            "3739405/3739405 [==============================] - 104s 28us/step - loss: 0.5644 - acc: 0.6923 - val_loss: 0.5531 - val_acc: 0.7435\n",
            "Epoch 6/10\n",
            "3739405/3739405 [==============================] - 104s 28us/step - loss: 0.5616 - acc: 0.6945 - val_loss: 0.5536 - val_acc: 0.7414\n",
            "Epoch 7/10\n",
            "3739405/3739405 [==============================] - 104s 28us/step - loss: 0.5594 - acc: 0.6956 - val_loss: 0.5463 - val_acc: 0.7458\n",
            "Epoch 8/10\n",
            "3739405/3739405 [==============================] - 104s 28us/step - loss: 0.5573 - acc: 0.6971 - val_loss: 0.5463 - val_acc: 0.7477\n",
            "Epoch 9/10\n",
            "3739405/3739405 [==============================] - 104s 28us/step - loss: 0.5559 - acc: 0.6978 - val_loss: 0.5613 - val_acc: 0.7349\n",
            "Epoch 10/10\n",
            "3739405/3739405 [==============================] - 105s 28us/step - loss: 0.5545 - acc: 0.6988 - val_loss: 0.5542 - val_acc: 0.7422\n",
            "Trained in 17 minutes, 26 seconds\n",
            "Copying file:///content/emilySaturdayNight_model_0_party_1574571887.0150244.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/8.2 MiB.                                      \n",
            "Proportion of predictions for Republican class: 0.8463775204668792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training Model 1\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roPRjxAWgFN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}