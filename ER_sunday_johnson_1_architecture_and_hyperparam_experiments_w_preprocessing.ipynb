{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "architecture_and_hyperparam_experiments_w_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/ER_sunday_johnson_1_architecture_and_hyperparam_experiments_w_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHeoGlIX2sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"emilySundayJohnson\"\n",
        "\n",
        "hyp_combos = [  \n",
        "               {'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 2,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "               {'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 40,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 4,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "             {'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 1,\n",
        "                'CONV_LAYER_SIZE': 256,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "               {'ARCHITECTURE': 'JOHNSON',\n",
        "                 'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 150,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 6,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "             \n",
        "               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh1bBq9Vw_8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4c3b3284-630f-4a1f-c56b-7a22bc5189d9"
      },
      "source": [
        " {'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'BYO',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZES': [128, 128],\n",
              "  'DROPOUT_RATES': [0.2, 0.2],\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [4, 4],\n",
              "  'FINAL_DENSE_LAYER_SIZE': 10,\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 1,\n",
              "  'NUM_LAYERS': 2,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2b471a4c-eb19-4e60-dfbd-9f0810fdd73a"
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "    assert 2**(hyp_combo['NUM_BLOCKS']+1) < hyp_combo['MAX_SEQUENCE_LENGTH']\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n",
            "Model 1 passed\n",
            "Model 2 passed\n",
            "Model 3 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "outputId": "f4520bbc-474a-467d-e912-e5465e367760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "outputId": "7b4859fa-6a07-4e95-843e-a36ebd51e78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "/ [4 files][  2.1 GiB/  2.1 GiB]  114.8 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "\\ [5 files][  2.9 GiB/  2.9 GiB]  121.0 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(1)\n",
        "        else:\n",
        "            final_list.append(0)\n",
        "    male = sum(final_list)\n",
        "    female = len(final_list)-sum(final_list)\n",
        "    percent_male = sum(final_list)/len(final_list)\n",
        "    print('total M: {}, total W: {}, percent M: {}'.format(male,female,percent_male))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(1)\n",
        "        else:\n",
        "            final_list.append(0)\n",
        "    republican = sum(final_list)\n",
        "    not_repub = len(final_list)-sum(final_list)\n",
        "    percent_repub = sum(final_list)/len(final_list)\n",
        "    print('total republican: {}, total not republican: {}, percent republican: {}'.format(republican,not_repub,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'M'\n",
        "  else:\n",
        "    return 'W'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Republican'\n",
        "  else:\n",
        "    return 'Not_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(.5)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "outputId": "193b4c85-f58d-4fd5-cba4-b7c26765005a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Republican' in dev_df.preds2.value_counts():\n",
        "    proportion_republican_predicted = dev_df.preds2.value_counts()['Congress_Republican'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_republican_predicted = 0\n",
        "  print(\"Proportion of predictions for Republican class: {}\".format(proportion_republican_predicted))\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755947 training rows\n",
            "Responses include only the first 10 and last 10 words\n",
            "Getting labels\n",
            "training set:\n",
            "total M: 2752041, total W: 1003906, percent M: 0.7327156107367863\n",
            "dev set:\n",
            "total M: 1821965, total W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "total republican: 2337054, total not republican: 1402563, percent republican: 0.6249447470155366\n",
            "dev set:\n",
            "total republican: 1593280, total not republican: 557512, percent republican: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 16 seconds\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 20, 50)            250150    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 20, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_45 (Conv1D)           (None, 20, 128)           19328     \n",
            "_________________________________________________________________\n",
            "conv1d_46 (Conv1D)           (None, 20, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_47 (Conv1D)           (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "conv1d_48 (Conv1D)           (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_24 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 417,447\n",
            "Trainable params: 167,297\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 3755947 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3755947/3755947 [==============================] - 56s 15us/step - loss: 0.5237 - acc: 0.7629 - val_loss: 0.4471 - val_acc: 0.8349\n",
            "Epoch 2/10\n",
            "3755947/3755947 [==============================] - 55s 15us/step - loss: 0.5057 - acc: 0.7719 - val_loss: 0.4257 - val_acc: 0.8464\n",
            "Epoch 3/10\n",
            "3755947/3755947 [==============================] - 55s 15us/step - loss: 0.5000 - acc: 0.7745 - val_loss: 0.4306 - val_acc: 0.8442\n",
            "Epoch 4/10\n",
            "3755947/3755947 [==============================] - 55s 15us/step - loss: 0.4962 - acc: 0.7765 - val_loss: 0.4268 - val_acc: 0.8429\n",
            "Epoch 5/10\n",
            "3755947/3755947 [==============================] - 56s 15us/step - loss: 0.4940 - acc: 0.7775 - val_loss: 0.4228 - val_acc: 0.8463\n",
            "Epoch 6/10\n",
            "3755947/3755947 [==============================] - 56s 15us/step - loss: 0.4924 - acc: 0.7782 - val_loss: 0.4295 - val_acc: 0.8450\n",
            "Epoch 7/10\n",
            "3755947/3755947 [==============================] - 55s 15us/step - loss: 0.4910 - acc: 0.7789 - val_loss: 0.4267 - val_acc: 0.8450\n",
            "Epoch 8/10\n",
            "3755947/3755947 [==============================] - 54s 14us/step - loss: 0.4902 - acc: 0.7792 - val_loss: 0.4206 - val_acc: 0.8469\n",
            "Epoch 9/10\n",
            "3755947/3755947 [==============================] - 54s 14us/step - loss: 0.4892 - acc: 0.7797 - val_loss: 0.4151 - val_acc: 0.8478\n",
            "Epoch 10/10\n",
            "3755947/3755947 [==============================] - 53s 14us/step - loss: 0.4884 - acc: 0.7800 - val_loss: 0.4194 - val_acc: 0.8466\n",
            "Trained in 09 minutes, 08 seconds\n",
            "Copying file:///content/emilySundayJohnson_model_0_gender_1574625506.736423.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/2.9 MiB.                                      \n",
            "Proportion of predictions for W class: 0.03253778143121232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkDAzsywHCTMzy/r/mPFqyN05tFMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739617 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.6157 - acc: 0.6575 - val_loss: 0.6049 - val_acc: 0.7032\n",
            "Epoch 2/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5918 - acc: 0.6740 - val_loss: 0.5890 - val_acc: 0.7251\n",
            "Epoch 3/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5833 - acc: 0.6799 - val_loss: 0.5806 - val_acc: 0.7295\n",
            "Epoch 4/10\n",
            "3739617/3739617 [==============================] - 54s 15us/step - loss: 0.5782 - acc: 0.6831 - val_loss: 0.5504 - val_acc: 0.7465\n",
            "Epoch 5/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5749 - acc: 0.6855 - val_loss: 0.5645 - val_acc: 0.7402\n",
            "Epoch 6/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5722 - acc: 0.6871 - val_loss: 0.5491 - val_acc: 0.7466\n",
            "Epoch 7/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5702 - acc: 0.6885 - val_loss: 0.5559 - val_acc: 0.7432\n",
            "Epoch 8/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5684 - acc: 0.6895 - val_loss: 0.5476 - val_acc: 0.7457\n",
            "Epoch 9/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5671 - acc: 0.6905 - val_loss: 0.5448 - val_acc: 0.7449\n",
            "Epoch 10/10\n",
            "3739617/3739617 [==============================] - 55s 15us/step - loss: 0.5660 - acc: 0.6912 - val_loss: 0.5555 - val_acc: 0.7458\n",
            "Trained in 09 minutes, 08 seconds\n",
            "Copying file:///content/emilySundayJohnson_model_0_party_1574625506.736423.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/2.9 MiB.                                      \n",
            "Proportion of predictions for Republican class: 0.8768244442047395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5SRhZmalnCTMzKzU/wcCoAwYES08UgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training Model 1\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3756161 training rows\n",
            "Responses include only the first 20 and last 20 words\n",
            "Getting labels\n",
            "training set:\n",
            "total M: 2751659, total W: 1004502, percent M: 0.7325721661025713\n",
            "dev set:\n",
            "total M: 1821965, total W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "total republican: 2336897, total not republican: 1402947, percent republican: 0.6248648339342496\n",
            "dev set:\n",
            "total republican: 1593280, total not republican: 557512, percent republican: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 25 seconds\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 40, 50)            250150    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 40, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_53 (Conv1D)           (None, 40, 128)           19328     \n",
            "_________________________________________________________________\n",
            "conv1d_54 (Conv1D)           (None, 40, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_27 (MaxPooling (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_55 (Conv1D)           (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "conv1d_56 (Conv1D)           (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_57 (Conv1D)           (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "conv1d_58 (Conv1D)           (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_59 (Conv1D)           (None, 4, 128)            49280     \n",
            "_________________________________________________________________\n",
            "conv1d_60 (Conv1D)           (None, 4, 128)            49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_30 (MaxPooling (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 614,567\n",
            "Trainable params: 364,417\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 3756161 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3756161/3756161 [==============================] - 106s 28us/step - loss: 0.5186 - acc: 0.7651 - val_loss: 0.4251 - val_acc: 0.8482\n",
            "Epoch 2/10\n",
            "3756161/3756161 [==============================] - 106s 28us/step - loss: 0.4999 - acc: 0.7743 - val_loss: 0.4298 - val_acc: 0.8476\n",
            "Epoch 3/10\n",
            "3756161/3756161 [==============================] - 107s 28us/step - loss: 0.4937 - acc: 0.7773 - val_loss: 0.4259 - val_acc: 0.8453\n",
            "Epoch 4/10\n",
            "3756161/3756161 [==============================] - 105s 28us/step - loss: 0.4903 - acc: 0.7788 - val_loss: 0.4220 - val_acc: 0.8456\n",
            "Epoch 5/10\n",
            "3756161/3756161 [==============================] - 105s 28us/step - loss: 0.4879 - acc: 0.7801 - val_loss: 0.4210 - val_acc: 0.8486\n",
            "Epoch 6/10\n",
            "3756161/3756161 [==============================] - 104s 28us/step - loss: 0.4860 - acc: 0.7808 - val_loss: 0.4219 - val_acc: 0.8488\n",
            "Epoch 7/10\n",
            "3756161/3756161 [==============================] - 104s 28us/step - loss: 0.4848 - acc: 0.7814 - val_loss: 0.4216 - val_acc: 0.8466\n",
            "Epoch 8/10\n",
            "3756161/3756161 [==============================] - 104s 28us/step - loss: 0.4835 - acc: 0.7820 - val_loss: 0.4298 - val_acc: 0.8435\n",
            "Epoch 9/10\n",
            "3756161/3756161 [==============================] - 104s 28us/step - loss: 0.4826 - acc: 0.7824 - val_loss: 0.4210 - val_acc: 0.8470\n",
            "Epoch 10/10\n",
            "3756161/3756161 [==============================] - 104s 28us/step - loss: 0.4818 - acc: 0.7826 - val_loss: 0.4169 - val_acc: 0.8463\n",
            "Trained in 17 minutes, 30 seconds\n",
            "Copying file:///content/emilySundayJohnson_model_1_gender_1574625506.736423.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/5.2 MiB.                                      \n",
            "Proportion of predictions for W class: 0.03574404219468921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739844 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3739844/3739844 [==============================] - 106s 28us/step - loss: 0.6083 - acc: 0.6622 - val_loss: 0.5961 - val_acc: 0.7161\n",
            "Epoch 2/10\n",
            "3739844/3739844 [==============================] - 103s 28us/step - loss: 0.5824 - acc: 0.6802 - val_loss: 0.6027 - val_acc: 0.7152\n",
            "Epoch 3/10\n",
            "3739844/3739844 [==============================] - 104s 28us/step - loss: 0.5732 - acc: 0.6867 - val_loss: 0.5663 - val_acc: 0.7341\n",
            "Epoch 4/10\n",
            "3739844/3739844 [==============================] - 104s 28us/step - loss: 0.5679 - acc: 0.6903 - val_loss: 0.5797 - val_acc: 0.7327\n",
            "Epoch 5/10\n",
            "3739844/3739844 [==============================] - 104s 28us/step - loss: 0.5643 - acc: 0.6925 - val_loss: 0.5628 - val_acc: 0.7389\n",
            "Epoch 6/10\n",
            "3739844/3739844 [==============================] - 104s 28us/step - loss: 0.5616 - acc: 0.6942 - val_loss: 0.5475 - val_acc: 0.7439\n",
            "Epoch 7/10\n",
            "3739844/3739844 [==============================] - 104s 28us/step - loss: 0.5593 - acc: 0.6956 - val_loss: 0.5633 - val_acc: 0.7328\n",
            "Epoch 8/10\n",
            "3739844/3739844 [==============================] - 106s 28us/step - loss: 0.5576 - acc: 0.6969 - val_loss: 0.5669 - val_acc: 0.7331\n",
            "Epoch 9/10\n",
            "3739844/3739844 [==============================] - 105s 28us/step - loss: 0.5562 - acc: 0.6978 - val_loss: 0.5589 - val_acc: 0.7345\n",
            "Epoch 10/10\n",
            "3739844/3739844 [==============================] - 105s 28us/step - loss: 0.5547 - acc: 0.6987 - val_loss: 0.5637 - val_acc: 0.7366\n",
            "Trained in 17 minutes, 26 seconds\n",
            "Copying file:///content/emilySundayJohnson_model_1_party_1574625506.736423.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/5.2 MiB.                                      \n",
            "Proportion of predictions for Republican class: 0.8358944054097281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCTMzy3KSMDOzLCcJMzPLcpIwM7Os/w+q6L8eCHMoAAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training Model 2\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755891 training rows\n",
            "Responses include only the first 10 and last 10 words\n",
            "Getting labels\n",
            "training set:\n",
            "total M: 2751638, total W: 1004253, percent M: 0.7326192373527347\n",
            "dev set:\n",
            "total M: 1821965, total W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "total republican: 2336867, total not republican: 1402716, percent republican: 0.6249004233894527\n",
            "dev set:\n",
            "total republican: 1593280, total not republican: 557512, percent republican: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 10 seconds\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 20, 50)            250150    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 20, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_69 (Conv1D)           (None, 20, 256)           38656     \n",
            "_________________________________________________________________\n",
            "conv1d_70 (Conv1D)           (None, 20, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_35 (MaxPooling (None, 9, 256)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_9 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 485,927\n",
            "Trainable params: 235,777\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 3755891 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3755891/3755891 [==============================] - 69s 18us/step - loss: 0.5238 - acc: 0.7636 - val_loss: 0.4574 - val_acc: 0.8425\n",
            "Epoch 2/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.5045 - acc: 0.7730 - val_loss: 0.4441 - val_acc: 0.8419\n",
            "Epoch 3/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4986 - acc: 0.7757 - val_loss: 0.4347 - val_acc: 0.8455\n",
            "Epoch 4/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4955 - acc: 0.7771 - val_loss: 0.4440 - val_acc: 0.8418\n",
            "Epoch 5/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4933 - acc: 0.7781 - val_loss: 0.4368 - val_acc: 0.8424\n",
            "Epoch 6/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4915 - acc: 0.7788 - val_loss: 0.4283 - val_acc: 0.8451\n",
            "Epoch 7/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4902 - acc: 0.7794 - val_loss: 0.4273 - val_acc: 0.8473\n",
            "Epoch 8/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4892 - acc: 0.7798 - val_loss: 0.4234 - val_acc: 0.8477\n",
            "Epoch 9/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4882 - acc: 0.7803 - val_loss: 0.4346 - val_acc: 0.8441\n",
            "Epoch 10/10\n",
            "3755891/3755891 [==============================] - 67s 18us/step - loss: 0.4875 - acc: 0.7806 - val_loss: 0.4343 - val_acc: 0.8446\n",
            "Trained in 11 minutes, 11 seconds\n",
            "Copying file:///content/emilySundayJohnson_model_2_gender_1574625506.736423.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/3.7 MiB.                                      \n",
            "Proportion of predictions for W class: 0.03955752113639999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZTlImJlZloOEmZll/X+eZnclSPeuagAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739583 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3308000/3739583 [=========================>....] - ETA: 7s - loss: 0.6178 - acc: 0.6577Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roPRjxAWgFN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyp_dict = {'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 100,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 3,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 4,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}\n",
        "model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}