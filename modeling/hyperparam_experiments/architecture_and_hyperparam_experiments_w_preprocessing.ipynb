{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "architecture_and_hyperparam_experiments_w_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/architecture_and_hyperparam_experiments_w_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHeoGlIX2sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"test\"\n",
        "\n",
        "hyp_combos = [  \n",
        "                  {'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 256,\n",
        "                'FILTER_SIZES': [3, 4, 5],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "              {'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZES': [3, 4, 5],\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "                {'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "              {'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 64,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyp1cqW7BHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e004e102-ed94-48ba-a7a8-718094a3ffcd"
      },
      "source": [
        "# examples of all the hyp dicts for each arch\n",
        "{'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "{'ARCHITECTURE': 'JOHNSON',\n",
        "                 'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 15,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "{'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 64,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'KIM',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZE': 64,\n",
              "  'DROPOUT_RATE': 0.2,\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [2, 4, 6],\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 10,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d23045df-77c1-4470-ec64-0a1fd0c40e2a"
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n",
            "Model 1 passed\n",
            "Model 2 passed\n",
            "Model 3 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "307a2023-0bf6-4f26-ca4e-5ba1c905c70f"
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/65/e2/05f903ce8f77804127195cfcc1ca8b500a3157a1572dcc4b82bf5af01564/gcsfs-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.4.0\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "1dc67f83-6652-41f4-c3d7-617be4171f30"
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "\\ [4 files][  2.1 GiB/  2.1 GiB]  108.2 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "| [5 files][  2.9 GiB/  2.9 GiB]  151.9 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(1)\n",
        "        else:\n",
        "            final_list.append(0)\n",
        "    male = sum(final_list)\n",
        "    female = len(final_list)-sum(final_list)\n",
        "    percent_male = sum(final_list)/len(final_list)\n",
        "    print('total M: {}, total W: {}, percent M: {}'.format(male,female,percent_male))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(1)\n",
        "        else:\n",
        "            final_list.append(0)\n",
        "    republican = sum(final_list)\n",
        "    not_repub = len(final_list)-sum(final_list)\n",
        "    percent_repub = sum(final_list)/len(final_list)\n",
        "    print('total republican: {}, total not republican: {}, percent republican: {}'.format(republican,not_repub,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'M'\n",
        "  else:\n",
        "    return 'W'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Republican'\n",
        "  else:\n",
        "    return 'Not_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes,\n",
        "                   dropout_rate):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(dropout_rate)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'],\n",
        "                           hyp_dict['DROPOUT_RATE'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46f87435-7736-480e-9bf3-6008a20c7394"
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Republican' in dev_df.preds2.value_counts():\n",
        "    proportion_republican_predicted = dev_df.preds2.value_counts()['Congress_Republican'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_republican_predicted = 0\n",
        "  print(\"Proportion of predictions for Republican class: {}\".format(proportion_republican_predicted))\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755947 training rows\n",
            "Responses include only the first 10 and last 10 words\n",
            "Getting labels\n",
            "training set:\n",
            "total M: 2752041, total W: 1003906, percent M: 0.7327156107367863\n",
            "dev set:\n",
            "total M: 1821965, total W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "total republican: 2337054, total not republican: 1402563, percent republican: 0.6249447470155366\n",
            "dev set:\n",
            "total republican: 1593280, total not republican: 557512, percent republican: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 06 seconds\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 50)       250150      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 18, 256)      38656       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 17, 256)      51456       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 16, 256)      64256       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 51, 256)      0           conv1d_1[0][0]                   \n",
            "                                                                 conv1d_2[0][0]                   \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 256)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            257         global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1)            0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 404,775\n",
            "Trainable params: 154,625\n",
            "Non-trainable params: 250,150\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3755947 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3755947/3755947 [==============================] - 54s 14us/step - loss: 7.5923 - acc: 0.3518 - val_loss: 1.4658 - val_acc: 0.5309\n",
            "Epoch 2/10\n",
            "3755947/3755947 [==============================] - 50s 13us/step - loss: 8.7426 - acc: 0.2397 - val_loss: 1.6189 - val_acc: 0.7744\n",
            "Epoch 3/10\n",
            "3755947/3755947 [==============================] - 50s 13us/step - loss: 8.6048 - acc: 0.1982 - val_loss: 2.1000 - val_acc: 0.7402\n",
            "Epoch 4/10\n",
            "3755947/3755947 [==============================] - 50s 13us/step - loss: 7.9906 - acc: 0.1740 - val_loss: 2.0328 - val_acc: 0.8260\n",
            "Epoch 5/10\n",
            "3755947/3755947 [==============================] - 51s 13us/step - loss: 8.0804 - acc: 0.1712 - val_loss: 2.1791 - val_acc: 0.8266\n",
            "Epoch 6/10\n",
            "3755947/3755947 [==============================] - 51s 14us/step - loss: 7.7917 - acc: 0.1582 - val_loss: 2.2478 - val_acc: 0.8449\n",
            "Epoch 7/10\n",
            "3755947/3755947 [==============================] - 51s 13us/step - loss: 7.7690 - acc: 0.1543 - val_loss: 2.2566 - val_acc: 0.8477\n",
            "Epoch 8/10\n",
            "3755947/3755947 [==============================] - 51s 14us/step - loss: 7.7516 - acc: 0.1560 - val_loss: 2.2853 - val_acc: 0.8489\n",
            "Epoch 9/10\n",
            "3755947/3755947 [==============================] - 51s 13us/step - loss: 7.8693 - acc: 0.1613 - val_loss: 2.4223 - val_acc: 0.8322\n",
            "Epoch 10/10\n",
            "3755947/3755947 [==============================] - 50s 13us/step - loss: 7.7785 - acc: 0.1593 - val_loss: 9.2986 - val_acc: 0.2958\n",
            "Trained in 08 minutes, 28 seconds\n",
            "Copying file:///content/emilySundayKim_model_0_gender_1574621227.317281.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/2.8 MiB.                                      \n",
            "Proportion of predictions for W class: 0.8087667240718768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEICAYAAABxiqLiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5ydVX3v8c+XhEu4X6JTSCLBGtQA\ntcUppPqyZyQ2BGoNx4MaihJoJEcBbWtaCb2cWDCn2BZTQUFTkybxpIQUbZO2wTQFdqk9JgREiUEp\nYwhkwiWSGwwIGPz1j2cNPGz3nj2z9mRPhvm+X695zbN/a61nrfXsPfu3n8ueRxGBmZlZfx0w2AMw\nM7OhyQnEzMyyOIGYmVkWJxAzM8viBGJmZlmcQMzMLIsTyGuQpM9I+n+ZbS+W9K1eyiuSPpqWL5T0\nr73UfZekB3PG0WCMH5f0pKRuSccN9Pr3tUbbeH8jKSS9KS1/WdKfZq6nW9IbB3Z0rdGf50zSYkmf\n3ddj2h84gewnJG2R9JP0R/ZkehEePtjj6k1ELIuIKT2Py280qfw/IuLNA9mnpAOBzwNTIuLwiNgx\nQOudLmm9pGclbU/Ll0nSQKx/X0pJ/fn02nlK0jckHb8v+oqIj0XENX0c00er2h4eEZv3xbhK/Y5P\nr8P7quKjJb0oacu+7L8vJP22pEfSa+0fJR072GPK5QSyf/mtiDgcOB1oB/6kuoIKw/l5awMOATb1\nt2G9bSdpNvAF4C+BX0h9fAx4J3BQU6MdYJJG1Cm6Ir12TgaOBub3s/1rzaGSTi09/m3g4cEaTA9J\npwBfAT5C8Tp7DrhxUAfVhOH8RrTfiohtwG3AqfDyp7l5kv6T4gX3RkknSFolaaekTkmXVq3mEEm3\nSHpG0nckva2nQNIcST9KZQ9I+p9VbSXpi5L2SPqhpMm1xlnerZd0Vwp/L30S/pCkDkldpfonSPq6\npB9LeljSJ0tlZ0i6R9LTaQ/s8zX6OxnoOSS2W9IdKf4OSRvSeDdIekepzc9tu6p1HgVcDVwWEbdG\nxDNRuC8iLoyIF1K9gyX9laRH0/i+LGlUKuuQ1CVpdtp7eVzSJaU+jkvP1dOS7gZ+sWoMb5G0Nj2X\nD0r6YKlssaSbJK2W9Czw7lrPRY+I2Al8nVdeOz/Xvre5pDZ/mObwmKTfqRrrqw7PSJom6btpbj+S\nNFXSPOBdwBfTa+GLqW75UNhRkpam18Ijkv6kJ7n3vK7SGHel18o5vc27hq8BM0qPLwKWVs3lren1\nsVvSJknvK5VlP2cNXAj8U0TcFRHdwJ8C75d0RD/nt3+ICP/sBz/AFuA9aXkcxSfsa9LjCvAocAow\nEjgQuIvik8shwC8DPwbOSvU/A/wUOD/V/QOKT18HpvIPACdQfID4EPAscHwquxjYC/x+avshYA9w\nbGksHy3V/VZpDgG8qfS4A+hKywcA9wL/h+JT/RuBzcDZqfzbwEfS8uHApDrbaXzqZ2R6fCywi+IT\n3UjggvT4uHrbrmp9U9N8RzZ4fuYDq1J/RwD/BPx5aZ57KRLRgcC5FMnqmFS+HFgBHEbxxr6tZ7ul\n2FbgkjS+XwGeAiam8sVp+78zbcNDaoyt/JyMBu4AvlavfYO5TAWeTOM8DPi78vOa1vfZtHxGWvdv\npHWPAd5SPaZarw+KN/OVqf/xwH8BM0uvq58ClwIjgI8DjwHqw99Rz+tjfNquI4CJwA+B9wBbUr0D\ngU7gjyhej2cBzwBvHqDn7LN1xrcSuLIq1g28fbDfg7LetwZ7AP5JT0SRQLqB3cAjFMlhVCqrAFeX\n6o4DXgKOKMX+HFiclj8DrCuVHQA8DryrTt/fBaal5Yur/1iBu3nlzf3lNwb6l0DOBB6t6vcq4G/T\n8l3AnwGjG2ynnjeIngTyEeDuqjrfBi6ute1qrO/DwBNVsf+fnoefAL8OiCLJ/mKpzq8BD5fm+RNK\nSQjYDkyieAP7KemNNZX939Kb0YeA/6jq/yvA3LS8GFjaYJtUKBLWboo3umXA62q178NcFgHXlspO\npn4C+Qowv5cx1UwgaZu8SHrDTWX/G6iUXledpbJDU9tf6MPf0cuvD+DfgLOBa4E/5tUJ5F3AE8AB\npbY3U/ztDMRzVi+B3A58rCq2DehoNLf98Wcktj85LyL+rU7Z1tLyCcDOiHimFHuE4rzJz9WPiJ+l\nQ0knAEi6CPgUxR8bFJ/4R5fabov0yi6t+4R+zKOWE4ETJO0uxUYA/5GWZ1J8gv+hpIeBP4uIf+7D\nek9I4yt7hOLTcI+t1LcDGC1pZETsBYiIdwCkbXYA8DqKN7F79co5daXxv7yenvbJcxTb9XUUb2bl\nMZTHeyJwZtV2GUlxCKYv4+/xyYj4ap2ycvtGczmBYk+x1lirjQNW92Fs1UZT7AGU1139nD3RsxAR\nz6Wx9veikqUUyegdFAnj5FLZCcDWiPhZjTEMxHNWTzdwZFXsSIq9nyHHCWToKL+hPwYcK+mIUhJ5\nA8UnmR7jehbSseWxwGOSTgT+BpgMfDsiXpL0XYo3kR5jJKmURN5AccijGVspPuVOqFUYEQ8BF6Sx\nvh+4VdJxEfFsg/U+RvEHXfYG4Jvl1ffS/tvAC8A0inMHtTxFsYdxShTnp/rjxxSHt8ZRHEbpGV+P\nrcC/R8Rv9LKOZv9ldrl9o7k8Tum1w6vHWm0rVecG6vRZ7SmKT/gnAg+U+unvtm3k68AXgXsj4tF0\nDq3HY8A4SQeUksgbKA6lDcRzVs8moHw+8o3AwanfIccn0YegiNhKcZjlzyUdIumXKD7Bl7/78XZJ\n75c0Evg9ijfJdRTHb4Pij4R0srd8tQrA64FPSjpQ0geAt9K3T5pPUnWSuuRu4BlJV0oaJWmEpFMl\n/Woax4clvS79Mfd8svtZnXWVrQZOVnFp5EhJH6I45t2XvRciYjfFobMbJZ0v6QhJB0j6ZYptRRrT\n3wDzJb0+jXeMpLP7sP6XgG8An5F0qKSJvPrk7j+n8X8kbe8DJf2qpLf2Zfz91Ye5rAAuljRR0qHA\n3F5WtxC4RNLktM3GSHpLKqv7WkjbZAUwL23vEyn2iPv03SUV33OqNKqXPnycBXy0RvF6ir3ET6dt\n3gH8FrB8Hz9ny4DfUvEdqcMo9rq/UXU0YchwAhm6LqA4BPUY8A8Ux1/Lh79WUhyr7TnB/P6I+GlE\nPABcR/HJ+0ngNOA/q9a9HphA8UlxHnB+9O37Fp8BlqSrWl51VUr6o3wvxQn/h9O6vwoclapMBTZJ\n6qa4pHZ6RPykUYdpXO8FZlMcjvo08N6IeKoP4+1Zx19QvIF9mmKbPElxTPtKikRNWu4E1kl6muL4\nel+/43IFxeGXJyiOj/9tqe9ngCnAdIrn8gngcxSfSveVunOJiNuAv6Y4Ed+ZftcUEXdTnEieT3Ey\n/d95ZW/wC8D56Sqq62s0/wTFuZjNwLcoTtYv6uP4x/Hzr9l6Y7wnIn5UI/4iRcI4h+K1eCNwUUT0\n7HHsk+csIjZRXCK+jOI82RHAZX2Zy/5Irz7UbWa2f0uHXCf38UON7UNOIGZmlsWHsMzMLIsTiJmZ\nZXECMTOzLMPmeyCjR4+O8ePHZ7V99tlnOeywwwZ2QPs5z3l48JyHh2bmfO+99z4VEa+rVTZsEsj4\n8eO55557stpWKhU6OjoGdkD7Oc95ePCch4dm5iyp7n8j8CEsMzPL4gRiZmZZnEDMzCyLE4iZmWVx\nAjEzsyxOIGZmlsUJxMzMsjiBmJlZFicQMzPLMmy+id6Mjdv2cPGcf8luv+Xa3xzA0ZiZ7R+8B2Jm\nZlmcQMzMLEvDBCJpkaTtkr5fFf+EpB9K2iTpL0rxqyR1SnpQ0tml+NQU65Q0pxQ/SdL6FL9F0kEp\nfnB63JnKxzfqw8zMWqcveyCLganlgKR3A9OAt0XEKcBfpfhEihvNn5La3ChphKQRwJcobmA/Ebgg\n1YXiZvTzI+JNwC5gZorPBHal+PxUr24f/Z+6mZk1o2ECiYi7gJ1V4Y8D10bEC6nO9hSfBiyPiBci\n4mGgEzgj/XRGxOaIeBFYDkyTJOAs4NbUfglwXmldS9LyrcDkVL9eH2Zm1kK5V2GdDLxL0jzgeeAP\nImIDMAZYV6rXlWIAW6viZwLHAbsjYm+N+mN62kTEXkl7Uv3e+ngVSbOAWQBtbW1UKpV+TxSgbRTM\nPm1v44p15PY7mLq7u4fkuJvhOQ8PnvPAyU0gI4FjgUnArwIrJL1xwEY1QCJiAbAAoL29PXJvqHLD\nspVctzH/iuctF+b1O5h8053hwXMeHvbVnHOvwuoCvhGFu4GfAaOBbcC4Ur2xKVYvvgM4WtLIqjjl\nNqn8qFS/3rrMzKyFchPIPwLvBpB0MnAQ8BSwCpierqA6CZgA3A1sACakK64OojgJvioiArgTOD+t\ndwawMi2vSo9J5Xek+vX6MDOzFmp4XEbSzUAHMFpSFzAXWAQsSpf2vgjMSG/umyStAB4A9gKXR8RL\naT1XAGuAEcCiiNiUurgSWC7ps8B9wMIUXwh8TVInxUn86QARUbcPMzNrnYYJJCIuqFP04Tr15wHz\nasRXA6trxDdT4yqqiHge+EB/+jAzs9bxN9HNzCyLE4iZmWVxAjEzsyxOIGZmlsUJxMzMsjiBmJlZ\nFicQMzPL4gRiZmZZnEDMzCyLE4iZmWVxAjEzsyxOIGZmlsUJxMzMsjiBmJlZFicQMzPL4gRiZmZZ\nGiYQSYskbU93H6wumy0pJI1OjyXpekmdku6XdHqp7gxJD6WfGaX42yVtTG2ul6QUP1bS2lR/raRj\nGvVhZmat05c9kMXA1OqgpHHAFODRUvgcinuUTwBmATelusdS3Ar3TIq7D87tSQipzqWldj19zQFu\nj4gJwO3pcd0+zMystRomkIi4i+Ke5NXmA58GohSbBiyNwjrgaEnHA2cDayNiZ0TsAtYCU1PZkRGx\nLt1TfSlwXmldS9Lykqp4rT7MzKyFGt4TvRZJ04BtEfG9dMSpxxhga+lxV4r1Fu+qEQdoi4jH0/IT\nQFuDPh6niqRZFHsptLW1UalU+jbBKm2jYPZpe7PaAtn9Dqbu7u4hOe5meM7Dg+c8cPqdQCQdCvwR\nxeGrloiIkBSNa/5cuwXAAoD29vbo6OjI6v+GZSu5bmNWrgVgy4V5/Q6mSqVC7vYaqjzn4cFzHjg5\nV2H9InAS8D1JW4CxwHck/QKwDRhXqjs2xXqLj60RB3iy59BU+r09xeuty8zMWqjfCSQiNkbE6yNi\nfESMpziEdHpEPAGsAi5KV0pNAvakw1BrgCmSjkknz6cAa1LZ05ImpauvLgJWpq5WAT1Xa82oitfq\nw8zMWqjhcRlJNwMdwGhJXcDciFhYp/pq4FygE3gOuAQgInZKugbYkOpdHRE9J+Yvo7jSaxRwW/oB\nuBZYIWkm8Ajwwd76MDOz1mqYQCLiggbl40vLAVxep94iYFGN+D3AqTXiO4DJNeJ1+zAzs9bxN9HN\nzCyLE4iZmWVxAjEzsyxOIGZmlsUJxMzMsjiBmJlZFicQMzPL4gRiZmZZnEDMzCyLE4iZmWVxAjEz\nsyxOIGZmlsUJxMzMsjiBmJlZFicQMzPL4gRiZmZZGiYQSYskbZf0/VLsLyX9UNL9kv5B0tGlsqsk\ndUp6UNLZpfjUFOuUNKcUP0nS+hS/RdJBKX5wetyZysc36sPMzFqnL3sgi4GpVbG1wKkR8UvAfwFX\nAUiaCEwHTkltbpQ0QtII4EvAOcBE4IJUF+BzwPyIeBOwC5iZ4jOBXSk+P9Wr20c/521mZk1qmEAi\n4i5gZ1XsXyNib3q4DhiblqcByyPihYh4mOK+5Wekn86I2BwRLwLLgWmSBJwF3JraLwHOK61rSVq+\nFZic6tfrw8zMWqjhPdH74HeAW9LyGIqE0qMrxQC2VsXPBI4DdpeSUbn+mJ42EbFX0p5Uv7c+XkXS\nLGAWQFtbG5VKpZ9TK7SNgtmn7W1csY7cfgdTd3f3kBx3Mzzn4cFzHjhNJRBJfwzsBZYNzHAGVkQs\nABYAtLe3R0dHR9Z6bli2kus25m+qLRfm9TuYKpUKudtrqPKchwfPeeBkvytKuhh4LzA5IiKFtwHj\nStXGphh14juAoyWNTHsh5fo96+qSNBI4KtXvrQ8zM2uRrMt4JU0FPg28LyKeKxWtAqanK6hOAiYA\ndwMbgAnpiquDKE6Cr0qJ507g/NR+BrCytK4Zafl84I5Uv14fZmbWQg33QCTdDHQAoyV1AXMprro6\nGFhbnNdmXUR8LCI2SVoBPEBxaOvyiHgprecKYA0wAlgUEZtSF1cCyyV9FrgPWJjiC4GvSeqkOIk/\nHaC3PszMrHUaJpCIuKBGeGGNWE/9ecC8GvHVwOoa8c3UuIoqIp4HPtCfPszMrHX8TXQzM8viBGJm\nZlmcQMzMLIsTiJmZZXECMTOzLE4gZmaWxQnEzMyyOIGYmVkWJxAzM8viBGJmZlmcQMzMLIsTiJmZ\nZXECMTOzLE4gZmaWxQnEzMyyOIGYmVmWhglE0iJJ2yV9vxQ7VtJaSQ+l38ekuCRdL6lT0v2STi+1\nmZHqPyRpRin+dkkbU5vrlW5xmNOHmZm1Tl/2QBYDU6tic4DbI2ICcHt6DHAOxT3KJwCzgJugSAYU\nt8I9k+Lug3N7EkKqc2mp3dScPszMrLUaJpCIuIvinuRl04AlaXkJcF4pvjQK64CjJR0PnA2sjYid\nEbELWAtMTWVHRsS6iAhgadW6+tOHmZm1UMN7otfRFhGPp+UngLa0PAbYWqrXlWK9xbtqxHP6eJwq\nkmZR7KXQ1tZGpVLp2+yqtI2C2aftzWoLZPc7mLq7u4fkuJvhOQ8PnvPAyU0gL4uIkBQDMZiB7iMi\nFgALANrb26OjoyOr/xuWreS6jfmbasuFef0OpkqlQu72Gqo85+HBcx44uVdhPdlz2Cj93p7i24Bx\npXpjU6y3+Nga8Zw+zMyshXITyCqg50qqGcDKUvyidKXUJGBPOgy1Bpgi6Zh08nwKsCaVPS1pUrr6\n6qKqdfWnDzMza6GGx2Uk3Qx0AKMldVFcTXUtsELSTOAR4IOp+mrgXKATeA64BCAidkq6BtiQ6l0d\nET0n5i+juNJrFHBb+qG/fZiZWWs1TCARcUGdosk16gZweZ31LAIW1YjfA5xaI76jv32YmVnr+Jvo\nZmaWxQnEzMyyOIGYmVkWJxAzM8viBGJmZlmcQMzMLIsTiJmZZXECMTOzLE4gZmaWxQnEzMyyOIGY\nmVkWJxAzM8viBGJmZlmcQMzMLIsTiJmZZXECMTOzLE0lEEm/L2mTpO9LulnSIZJOkrReUqekWyQd\nlOoenB53pvLxpfVcleIPSjq7FJ+aYp2S5pTiNfswM7PWyU4gksYAnwTaI+JUYAQwHfgcMD8i3gTs\nAmamJjOBXSk+P9VD0sTU7hRgKnCjpBGSRgBfAs4BJgIXpLr00oeZmbVIs4ewRgKjJI0EDgUeB84C\nbk3lS4Dz0vK09JhUPlmSUnx5RLwQEQ9T3Ov8jPTTGRGbI+JFYDkwLbWp14eZmbVIw3ui1xMR2yT9\nFfAo8BPgX4F7gd0RsTdV6wLGpOUxwNbUdq+kPcBxKb6utOpym61V8TNTm3p9vIqkWcAsgLa2NiqV\nStZc20bB7NP2Nq5YR26/g6m7u3tIjrsZnvPw4DkPnOwEIukYir2Hk4DdwN9THILab0TEAmABQHt7\ne3R0dGSt54ZlK7luY/amYsuFef0OpkqlQu72Gqo85+HBcx44zRzCeg/wcET8OCJ+CnwDeCdwdDqk\nBTAW2JaWtwHjAFL5UcCOcryqTb34jl76MDOzFmkmgTwKTJJ0aDovMRl4ALgTOD/VmQGsTMur0mNS\n+R0RESk+PV2ldRIwAbgb2ABMSFdcHURxon1ValOvDzMza5HsBBIR6ylOZH8H2JjWtQC4EviUpE6K\n8xULU5OFwHEp/ilgTlrPJmAFRfL5JnB5RLyUznFcAawBfgCsSHXppQ8zM2uR/AP7QETMBeZWhTdT\nXEFVXfd54AN11jMPmFcjvhpYXSNesw8zM2sdfxPdzMyyOIGYmVkWJxAzM8viBGJmZlmcQMzMLIsT\niJmZZXECMTOzLE4gZmaWxQnEzMyyOIGYmVkWJxAzM8viBGJmZlmcQMzMLIsTiJmZZXECMTOzLE4g\nZmaWpakEIuloSbdK+qGkH0j6NUnHSlor6aH0+5hUV5Kul9Qp6X5Jp5fWMyPVf0jSjFL87ZI2pjbX\np1vnUq8PMzNrnWb3QL4AfDMi3gK8jeLWs3OA2yNiAnB7egxwDsX9zicAs4CboEgGFHc1PJPiLoNz\nSwnhJuDSUrupKV6vDzMza5HsBCLpKODXSfcjj4gXI2I3MA1YkqotAc5Ly9OApVFYBxwt6XjgbGBt\nROyMiF3AWmBqKjsyItZFRABLq9ZVqw8zM2uRZu6JfhLwY+BvJb0NuBf4XaAtIh5PdZ4A2tLyGGBr\nqX1XivUW76oRp5c+XkXSLIq9Hdra2qhUKv2bYU9no2D2aXuz2gLZ/Q6m7u7uITnuZnjOw4PnPHCa\nSSAjgdOBT0TEeklfoOpQUkSEpGhmgI301kdELAAWALS3t0dHR0dWHzcsW8l1G/M31ZYL8/odTJVK\nhdztNVR5zsOD5zxwmjkH0gV0RcT69PhWioTyZDr8RPq9PZVvA8aV2o9Nsd7iY2vE6aUPMzNrkewE\nEhFPAFslvTmFJgMPAKuAniupZgAr0/Iq4KJ0NdYkYE86DLUGmCLpmHTyfAqwJpU9LWlSuvrqoqp1\n1erDzMxapJlDWACfAJZJOgjYDFxCkZRWSJoJPAJ8MNVdDZwLdALPpbpExE5J1wAbUr2rI2JnWr4M\nWAyMAm5LPwDX1unDzMxapKkEEhHfBdprFE2uUTeAy+usZxGwqEb8HuDUGvEdtfowM7PW8TfRzcws\nixOImZllcQIxM7MsTiBmZpbFCcTMzLI4gZiZWRYnEDMzy+IEYmZmWZxAzMwsixOImZllcQIxM7Ms\nTiBmZpbFCcTMzLI4gZiZWRYnEDMzy+IEYmZmWZpOIJJGSLpP0j+nxydJWi+pU9It6W6FSDo4Pe5M\n5eNL67gqxR+UdHYpPjXFOiXNKcVr9mFmZq0zEHsgvwv8oPT4c8D8iHgTsAuYmeIzgV0pPj/VQ9JE\nYDpwCjAVuDElpRHAl4BzgInABalub32YmVmLNJVAJI0FfhP4anos4Czg1lRlCXBeWp6WHpPKJ6f6\n04DlEfFCRDxMcc/0M9JPZ0RsjogXgeXAtAZ9mJlZizS7B/LXwKeBn6XHxwG7I2JvetwFjEnLY4Ct\nAKl8T6r/cryqTb14b32YmVmLjMxtKOm9wPaIuFdSx8ANaeBImgXMAmhra6NSqWStp20UzD5tb+OK\ndeT2O5i6u7uH5Lib4TkPD57zwMlOIMA7gfdJOhc4BDgS+AJwtKSRaQ9hLLAt1d8GjAO6JI0EjgJ2\nlOI9ym1qxXf00serRMQCYAFAe3t7dHR0ZE30hmUruW5j/qbacmFev4OpUqmQu72GKs95ePCcB072\nIayIuCoixkbEeIqT4HdExIXAncD5qdoMYGVaXpUek8rviIhI8enpKq2TgAnA3cAGYEK64uqg1Meq\n1KZeH2Zm1iL74nsgVwKfktRJcb5iYYovBI5L8U8BcwAiYhOwAngA+CZweUS8lPYurgDWUFzltSLV\n7a0PMzNrkWYOYb0sIipAJS1vpriCqrrO88AH6rSfB8yrEV8NrK4Rr9mHmZm1jr+JbmZmWZxAzMws\ny4AcwjIzs31r/Jx/yW67eOphAziSV3gPxMzMsjiBmJlZFicQMzPL4gRiZmZZnEDMzCyLE4iZmWVx\nAjEzsyxOIGZmlsUJxMzMsjiBmJlZFicQMzPL4gRiZmZZnEDMzCyLE4iZmWXJTiCSxkm6U9IDkjZJ\n+t0UP1bSWkkPpd/HpLgkXS+pU9L9kk4vrWtGqv+QpBml+NslbUxtrpek3vowM7PWaWYPZC8wOyIm\nApOAyyVNpLjX+e0RMQG4PT0GOAeYkH5mATdBkQyAucCZFLepnVtKCDcBl5baTU3xen2YmVmLZCeQ\niHg8Ir6Tlp8BfgCMAaYBS1K1JcB5aXkasDQK64CjJR0PnA2sjYidEbELWAtMTWVHRsS6iAhgadW6\navVhZmYtMiB3JJQ0HvgVYD3QFhGPp6IngLa0PAbYWmrWlWK9xbtqxOmlj+pxzaLY26GtrY1KpdK/\nifV0Ngpmn7Y3qy2Q3e9g6u7uHpLjbobnPDwM1Tk38x60r+bcdAKRdDjwdeD3IuLpdJoCgIgISdFs\nH73prY+IWAAsAGhvb4+Ojo6sPm5YtpLrNuZvqi0X5vU7mCqVCrnba6jynIeHoTrni5u8pe2+mHNT\nV2FJOpAieSyLiG+k8JPp8BPp9/YU3waMKzUfm2K9xcfWiPfWh5mZtUgzV2EJWAj8ICI+XypaBfRc\nSTUDWFmKX5SuxpoE7EmHodYAUyQdk06eTwHWpLKnJU1KfV1Uta5afZiZWYs0cwjrncBHgI2Svpti\nfwRcC6yQNBN4BPhgKlsNnAt0As8BlwBExE5J1wAbUr2rI2JnWr4MWAyMAm5LP/TSh5mZtUh2AomI\nbwGqUzy5Rv0ALq+zrkXAohrxe4BTa8R31OrDzMxax99ENzOzLE4gZmaWxQnEzMyyOIGYmVkWJxAz\nM8viBGJmZlmcQMzMLIsTiJmZZXECMTOzLE4gZmaWxQnEzMyyOIGYmVkWJxAzM8viBGJmZlmcQMzM\nLIsTiJmZZWnmjoSDTtJU4AvACOCrEXHtIA+ppvFz/iW77ZZrf3MAR2JmNnCGbAKRNAL4EvAbQBew\nQdKqiHhgcEc2sJx8zPYfzfw9vhYN2QQCnAF0RsRmAEnLgWnAayqBNKOZF/vs0/Zy8TD7Y/Gch4fh\nOOd9RcWtyoceSecDUyPio+nxR4AzI+KKUp1ZwKz08M3Ag5ndjQaeamK4Q5HnPDx4zsNDM3M+MSJe\nV6tgKO+BNBQRC4AFza5H0j0R0T4AQxoyPOfhwXMeHvbVnIfyVVjbgHGlx2NTzMzMWmAoJ5ANwARJ\nJ0k6CJgOrBrkMZmZDRtD9hBWROyVdAWwhuIy3kURsWkfddf0YbAhyHMeHjzn4WGfzHnInkQ3M7PB\nNZQPYZmZ2SByAjEzsyxOIOiOvYkAAANSSURBVCWSpkp6UFKnpDk1yg+WdEsqXy9pfOtHObD6MOdP\nSXpA0v2Sbpd04mCMcyA1mnOp3v+SFJKG/CWffZmzpA+m53qTpL9r9RgHWh9e22+QdKek+9Lr+9zB\nGOdAkbRI0nZJ369TLknXp+1xv6TTm+40IvxTnAcaAfwIeCNwEPA9YGJVncuAL6fl6cAtgz3uFsz5\n3cChafnjw2HOqd4RwF3AOqB9sMfdgud5AnAfcEx6/PrBHncL5rwA+HhanghsGexxNznnXwdOB75f\np/xc4DZAwCRgfbN9eg/kFS//a5SIeBHo+dcoZdOAJWn5VmCyJLVwjAOt4Zwj4s6IeC49XEfxfZuh\nrC/PM8A1wOeA51s5uH2kL3O+FPhSROwCiIjtLR7jQOvLnAM4Mi0fBTzWwvENuIi4C9jZS5VpwNIo\nrAOOlnR8M306gbxiDLC19LgrxWrWiYi9wB7guJaMbt/oy5zLZlJ8ghnKGs457dqPi4jXyj9M6svz\nfDJwsqT/lLQu/afroawvc/4M8GFJXcBq4BOtGdqg6e/fe0ND9nsg1lqSPgy0A/9jsMeyL0k6APg8\ncPEgD6XVRlIcxuqg2Mu8S9JpEbF7UEe1b10ALI6I6yT9GvA1SadGxM8Ge2BDhfdAXtGXf43ych1J\nIyl2e3e0ZHT7Rp/+HYyk9wB/DLwvIl5o0dj2lUZzPgI4FahI2kJxrHjVED+R3pfnuQtYFRE/jYiH\ngf+iSChDVV/mPBNYARAR3wYOofing69VA/7vn5xAXtGXf42yCpiRls8H7oh0dmqIajhnSb8CfIUi\neQz14+LQYM4RsSciRkfE+IgYT3He530Rcc/gDHdA9OW1/Y8Uex9IGk1xSGtzKwc5wPoy50eByQCS\n3kqRQH7c0lG21irgonQ11iRgT0Q83swKfQgriTr/GkXS1cA9EbEKWEixm9tJcbJq+uCNuHl9nPNf\nAocDf5+uF3g0It43aINuUh/n/JrSxzmvAaZIegB4CfjDiBiye9d9nPNs4G8k/T7FCfWLh/IHQkk3\nU3wIGJ3O68wFDgSIiC9TnOc5F+gEngMuabrPIby9zMxsEPkQlpmZZXECMTOzLE4gZmaWxQnEzMyy\nOIGYmVkWJxAzM8viBGJmZln+G4Y25JICmaPbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739617 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3739617/3739617 [==============================] - 51s 14us/step - loss: 6.4125 - acc: 0.4436 - val_loss: 9.2224 - val_acc: 0.2765\n",
            "Epoch 2/10\n",
            "3739617/3739617 [==============================] - 50s 13us/step - loss: 8.1356 - acc: 0.3623 - val_loss: 1.8635 - val_acc: 0.5718\n",
            "Epoch 3/10\n",
            "2700000/3739617 [====================>.........] - ETA: 12s - loss: 7.2150 - acc: 0.3449^C\n",
            "Proportion of predictions for Republican class: 0.2847862554817016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training Model 1\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755848 training rows\n",
            "Responses include only the first 10 and last 10 words\n",
            "Getting labels\n",
            "training set:\n",
            "total M: 2751682, total W: 1004166, percent M: 0.73263934003719\n",
            "dev set:\n",
            "total M: 1821965, total W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "total republican: 2336891, total not republican: 1402643, percent republican: 0.6249150295197209\n",
            "dev set:\n",
            "total republican: 1593280, total not republican: 557512, percent republican: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 07 seconds\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 20, 50)       250150      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 18, 128)      19328       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 17, 128)      25728       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 16, 128)      32128       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 51, 128)      0           conv1d_7[0][0]                   \n",
            "                                                                 conv1d_8[0][0]                   \n",
            "                                                                 conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 128)          0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            129         global_max_pooling1d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1)            0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 327,463\n",
            "Trainable params: 77,313\n",
            "Non-trainable params: 250,150\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3755848 samples, validate on 2150792 samples\n",
            "Epoch 1/10\n",
            "3755848/3755848 [==============================] - 33s 9us/step - loss: 6.2954 - acc: 0.4605 - val_loss: 1.2492 - val_acc: 0.1558\n",
            "Epoch 2/10\n",
            "1479000/3755848 [==========>...................] - ETA: 17s - loss: 6.2821 - acc: 0.4604Copying file:///content/emilySundayKim_model_1_gender_1574621227.317281.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/1.9 MiB.                                      \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-27697ea96565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mdev_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0mdev_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preds'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_to_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}