{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_experiments_BYO_6gender.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/final_experiments_BYO_6gender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQFENKGqCqlR",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"Mon11_25_BYO6_idx40\"\n",
        "\n",
        "hyp_combos = [{'ARCHITECTURE': 'BYO',\n",
        "                'NUM_EPOCHS': 30,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 3,\n",
        "                'CONV_LAYER_SIZES': [32,32,32],\n",
        "                'FILTER_SIZES': [2,2,2],\n",
        "                'DROPOUT_RATES': [.2,.2,.2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyp1cqW7BHY",
        "colab_type": "code",
        "outputId": "4c7140f8-aa5d-4b99-8ee7-40172f13d880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# examples of all the hyp dicts for each arch\n",
        "{'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "{'ARCHITECTURE': 'JOHNSON',\n",
        "                 'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 15,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "{'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 64,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'KIM',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZE': 64,\n",
              "  'DROPOUT_RATE': 0.2,\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [2, 4, 6],\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 10,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "outputId": "dade3f41-9108-4185-ff9b-194b15333702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "outputId": "16446206-34ef-463e-dba7-8ad4d3131401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, roc_curve, roc_auc_score, precision_recall_curve, auc\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/65/e2/05f903ce8f77804127195cfcc1ca8b500a3157a1572dcc4b82bf5af01564/gcsfs-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.4.0\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "53f6ba0d-5203-4fa0-e291-cca3946e3440"
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "\\ [4 files][  2.1 GiB/  2.1 GiB]   85.7 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "| [5 files][  2.9 GiB/  2.9 GiB]   29.4 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    female = sum(final_list)\n",
        "    male = len(final_list)-sum(final_list)\n",
        "    percent_M = male/len(final_list)\n",
        "    print('M: {}, W: {}, percent M: {}'.format(male,female,percent_M))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    democrat = sum(final_list)\n",
        "    republican = len(final_list)-sum(final_list)\n",
        "    percent_repub = republican/len(final_list)\n",
        "    print('R: {}, D: {}, percent R: {}'.format(republican,democrat,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'W'\n",
        "  else:\n",
        "    return 'M'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Democrat'\n",
        "  else:\n",
        "    return 'Congress_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes,\n",
        "                   dropout_rate):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(dropout_rate)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'],\n",
        "                           hyp_dict['DROPOUT_RATE'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f8de5ab-0632-4d7f-91bf-6a15618cdcd8"
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_gender,preds)\n",
        "  print(\"gender ROC_AUC:\",roc_auc_score(y_dev_gender,preds))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"gender precision:\",precision_score(y_dev_gender,preds.round()))\n",
        "  print(\"gender recall:\",recall_score(y_dev_gender,preds.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_gender,preds)\n",
        "  print(\"gender precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Democrat' in dev_df.preds2.value_counts():\n",
        "    proportion_dem_predicted = dev_df.preds2.value_counts()['Congress_Democrat'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_dem_predicted = 0\n",
        "  print(\"Proportion of predictions for Democrat class: {}\".format(proportion_dem_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_party,preds2)\n",
        "  print(\"party ROC_AUC:\",roc_auc_score(y_dev_party,preds2))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"party precision:\",precision_score(y_dev_party,preds2.round()))\n",
        "  print(\"party recall:\",recall_score(y_dev_party,preds2.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_party,preds2)\n",
        "  print(\"party precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755947 training rows\n",
            "Responses include only the first 10 and last 10 words\n",
            "Getting labels\n",
            "training set:\n",
            "M: 2752041, W: 1003906, percent M: 0.7327156107367863\n",
            "dev set:\n",
            "M: 1821965, W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "R: 2337054, D: 1402563, percent R: 0.6249447470155366\n",
            "dev set:\n",
            "R: 1593280, D: 557512, percent R: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 22 seconds\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 50)            250150    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 20, 32)            3232      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 20, 32)            2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 20, 32)            2080      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 20, 32)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 257,883\n",
            "Trainable params: 7,733\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3755947 samples, validate on 2150792 samples\n",
            "Epoch 1/30\n",
            "3755947/3755947 [==============================] - 80s 21us/step - loss: 0.5134 - acc: 0.7688 - val_loss: 0.4553 - val_acc: 0.8482\n",
            "Epoch 2/30\n",
            "3755947/3755947 [==============================] - 81s 22us/step - loss: 0.4934 - acc: 0.7782 - val_loss: 0.4513 - val_acc: 0.8476\n",
            "Epoch 3/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4901 - acc: 0.7796 - val_loss: 0.4431 - val_acc: 0.8489\n",
            "Epoch 4/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4886 - acc: 0.7803 - val_loss: 0.4475 - val_acc: 0.8485\n",
            "Epoch 5/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4873 - acc: 0.7808 - val_loss: 0.4578 - val_acc: 0.8485\n",
            "Epoch 6/30\n",
            "3755947/3755947 [==============================] - 80s 21us/step - loss: 0.4866 - acc: 0.7811 - val_loss: 0.4534 - val_acc: 0.8486\n",
            "Epoch 7/30\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.4861 - acc: 0.7813 - val_loss: 0.4514 - val_acc: 0.8487\n",
            "Epoch 8/30\n",
            "3755947/3755947 [==============================] - 77s 20us/step - loss: 0.4855 - acc: 0.7816 - val_loss: 0.4555 - val_acc: 0.8487\n",
            "Epoch 9/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4851 - acc: 0.7816 - val_loss: 0.4496 - val_acc: 0.8491\n",
            "Epoch 10/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4848 - acc: 0.7819 - val_loss: 0.4453 - val_acc: 0.8478\n",
            "Epoch 11/30\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.4845 - acc: 0.7820 - val_loss: 0.4541 - val_acc: 0.8477\n",
            "Epoch 12/30\n",
            "3755947/3755947 [==============================] - 78s 21us/step - loss: 0.4842 - acc: 0.7822 - val_loss: 0.4481 - val_acc: 0.8496\n",
            "Epoch 13/30\n",
            "3755947/3755947 [==============================] - 78s 21us/step - loss: 0.4840 - acc: 0.7821 - val_loss: 0.4495 - val_acc: 0.8487\n",
            "Epoch 14/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4838 - acc: 0.7824 - val_loss: 0.4513 - val_acc: 0.8479\n",
            "Epoch 15/30\n",
            "3755947/3755947 [==============================] - 78s 21us/step - loss: 0.4837 - acc: 0.7823 - val_loss: 0.4421 - val_acc: 0.8492\n",
            "Epoch 16/30\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.4836 - acc: 0.7823 - val_loss: 0.4465 - val_acc: 0.8488\n",
            "Epoch 17/30\n",
            "3755947/3755947 [==============================] - 77s 20us/step - loss: 0.4833 - acc: 0.7825 - val_loss: 0.4460 - val_acc: 0.8482\n",
            "Epoch 18/30\n",
            "3755947/3755947 [==============================] - 78s 21us/step - loss: 0.4832 - acc: 0.7825 - val_loss: 0.4512 - val_acc: 0.8484\n",
            "Epoch 19/30\n",
            "3755947/3755947 [==============================] - 75s 20us/step - loss: 0.4831 - acc: 0.7826 - val_loss: 0.4415 - val_acc: 0.8484\n",
            "Epoch 20/30\n",
            "3755947/3755947 [==============================] - 77s 20us/step - loss: 0.4831 - acc: 0.7825 - val_loss: 0.4448 - val_acc: 0.8489\n",
            "Epoch 21/30\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.4829 - acc: 0.7825 - val_loss: 0.4482 - val_acc: 0.8478\n",
            "Epoch 22/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4829 - acc: 0.7825 - val_loss: 0.4392 - val_acc: 0.8491\n",
            "Epoch 23/30\n",
            "3755947/3755947 [==============================] - 77s 20us/step - loss: 0.4827 - acc: 0.7827 - val_loss: 0.4403 - val_acc: 0.8484\n",
            "Epoch 24/30\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.4826 - acc: 0.7828 - val_loss: 0.4460 - val_acc: 0.8481\n",
            "Epoch 25/30\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.4826 - acc: 0.7827 - val_loss: 0.4425 - val_acc: 0.8484\n",
            "Epoch 26/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4824 - acc: 0.7828 - val_loss: 0.4459 - val_acc: 0.8494\n",
            "Epoch 27/30\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.4824 - acc: 0.7828 - val_loss: 0.4432 - val_acc: 0.8491\n",
            "Epoch 28/30\n",
            "3755947/3755947 [==============================] - 77s 20us/step - loss: 0.4823 - acc: 0.7829 - val_loss: 0.4384 - val_acc: 0.8493\n",
            "Epoch 29/30\n",
            "3755947/3755947 [==============================] - 78s 21us/step - loss: 0.4823 - acc: 0.7827 - val_loss: 0.4492 - val_acc: 0.8473\n",
            "Epoch 30/30\n",
            "3755947/3755947 [==============================] - 79s 21us/step - loss: 0.4821 - acc: 0.7828 - val_loss: 0.4416 - val_acc: 0.8485\n",
            "Trained in 39 minutes, 03 seconds\n",
            "Copying file:///content/Mon11_25_BYO6_idx40_model_0_gender_1574707759.9829493.h5 [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.1 MiB/  1.1 MiB]                                                \n",
            "Operation completed over 1 objects/1.1 MiB.                                      \n",
            "Proportion of predictions for W class: 0.019995424941137964\n",
            "gender ROC_AUC: 0.6620440012435879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "gender precision: 0.5348323489745617\n",
            "gender recall: 0.06994863560474049\n",
            "gender precision-recall AUC: 0.2874731872969101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZGYUyIQEYk5JQIRkZj7/92MvU0TJKdLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739617 samples, validate on 2150792 samples\n",
            "Epoch 1/30\n",
            "3739617/3739617 [==============================] - 80s 21us/step - loss: 0.6022 - acc: 0.6669 - val_loss: 0.5894 - val_acc: 0.7334\n",
            "Epoch 2/30\n",
            "3739617/3739617 [==============================] - 80s 21us/step - loss: 0.5755 - acc: 0.6855 - val_loss: 0.5803 - val_acc: 0.7371\n",
            "Epoch 3/30\n",
            "3739617/3739617 [==============================] - 80s 21us/step - loss: 0.5700 - acc: 0.6893 - val_loss: 0.5725 - val_acc: 0.7440\n",
            "Epoch 4/30\n",
            "3739617/3739617 [==============================] - 78s 21us/step - loss: 0.5674 - acc: 0.6910 - val_loss: 0.5723 - val_acc: 0.7416\n",
            "Epoch 5/30\n",
            "3739617/3739617 [==============================] - 80s 21us/step - loss: 0.5659 - acc: 0.6921 - val_loss: 0.5692 - val_acc: 0.7456\n",
            "Epoch 6/30\n",
            "3739617/3739617 [==============================] - 79s 21us/step - loss: 0.5645 - acc: 0.6929 - val_loss: 0.5748 - val_acc: 0.7430\n",
            "Epoch 7/30\n",
            "3739617/3739617 [==============================] - 80s 22us/step - loss: 0.5635 - acc: 0.6935 - val_loss: 0.5682 - val_acc: 0.7460\n",
            "Epoch 8/30\n",
            "3739617/3739617 [==============================] - 78s 21us/step - loss: 0.5629 - acc: 0.6938 - val_loss: 0.5670 - val_acc: 0.7435\n",
            "Epoch 9/30\n",
            "3739617/3739617 [==============================] - 78s 21us/step - loss: 0.5623 - acc: 0.6944 - val_loss: 0.5698 - val_acc: 0.7480\n",
            "Epoch 10/30\n",
            "3739617/3739617 [==============================] - 77s 21us/step - loss: 0.5618 - acc: 0.6945 - val_loss: 0.5730 - val_acc: 0.7442\n",
            "Epoch 11/30\n",
            "3739617/3739617 [==============================] - 79s 21us/step - loss: 0.5612 - acc: 0.6949 - val_loss: 0.5765 - val_acc: 0.7422\n",
            "Epoch 12/30\n",
            "3739617/3739617 [==============================] - 77s 21us/step - loss: 0.5610 - acc: 0.6951 - val_loss: 0.5650 - val_acc: 0.7466\n",
            "Epoch 13/30\n",
            "3739617/3739617 [==============================] - 78s 21us/step - loss: 0.5607 - acc: 0.6955 - val_loss: 0.5704 - val_acc: 0.7445\n",
            "Epoch 14/30\n",
            "3739617/3739617 [==============================] - 77s 21us/step - loss: 0.5605 - acc: 0.6955 - val_loss: 0.5686 - val_acc: 0.7428\n",
            "Epoch 15/30\n",
            "3739617/3739617 [==============================] - 79s 21us/step - loss: 0.5601 - acc: 0.6959 - val_loss: 0.5714 - val_acc: 0.7474\n",
            "Epoch 16/30\n",
            "3739617/3739617 [==============================] - 77s 21us/step - loss: 0.5600 - acc: 0.6958 - val_loss: 0.5661 - val_acc: 0.7431\n",
            "Epoch 17/30\n",
            " 997000/3739617 [======>.......................] - ETA: 51s - loss: 0.5591 - acc: 0.6968Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
