{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_experiments_johnson2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/final_experiments_johnson2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHeoGlIX2sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"Mon_11_25_johnson2\"\n",
        "\n",
        "hyp_combos = [{'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 20,\n",
        "                'BATCH_SIZE': 10000,\n",
        "                'MAX_SEQUENCE_LENGTH': 40,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 3,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyp1cqW7BHY",
        "colab_type": "code",
        "outputId": "9bfae4da-f9a7-4548-eebf-94b4b4dae88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# examples of all the hyp dicts for each arch\n",
        "{'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "{'ARCHITECTURE': 'JOHNSON',\n",
        "                 'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 15,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "{'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 64,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'KIM',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZE': 64,\n",
              "  'DROPOUT_RATE': 0.2,\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [2, 4, 6],\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 10,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "outputId": "b82ac41f-6fed-4097-f7c9-c614b9bdbc86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "outputId": "5ef9b333-9a36-429b-ee8a-ce411cfff915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, roc_curve, roc_auc_score, precision_recall_curve, auc\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "outputId": "6425d7fa-3db0-42e7-edb8-69301dfbde09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "- [4 files][  2.1 GiB/  2.1 GiB]   85.1 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "| [5 files][  2.9 GiB/  2.9 GiB]  138.5 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    female = sum(final_list)\n",
        "    male = len(final_list)-sum(final_list)\n",
        "    percent_M = male/len(final_list)\n",
        "    print('M: {}, W: {}, percent M: {}'.format(male,female,percent_M))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    democrat = sum(final_list)\n",
        "    republican = len(final_list)-sum(final_list)\n",
        "    percent_repub = republican/len(final_list)\n",
        "    print('R: {}, D: {}, percent R: {}'.format(republican,democrat,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'W'\n",
        "  else:\n",
        "    return 'M'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Democrat'\n",
        "  else:\n",
        "    return 'Congress_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes,\n",
        "                   dropout_rate):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(dropout_rate)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'],\n",
        "                           hyp_dict['DROPOUT_RATE'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "outputId": "5fdfd537-080a-404e-c03b-1d047f7d3275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_gender,preds)\n",
        "  print(\"gender ROC_AUC:\",roc_auc_score(y_dev_gender,preds))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"gender precision:\",precision_score(y_dev_gender,preds.round()))\n",
        "  print(\"gender recall:\",recall_score(y_dev_gender,preds.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_gender,preds)\n",
        "  print(\"gender precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Democrat' in dev_df.preds2.value_counts():\n",
        "    proportion_dem_predicted = dev_df.preds2.value_counts()['Congress_Democrat'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_dem_predicted = 0\n",
        "  print(\"Proportion of predictions for Democrat class: {}\".format(proportion_dem_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_party,preds2)\n",
        "  print(\"party ROC_AUC:\",roc_auc_score(y_dev_party,preds2))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"party precision:\",precision_score(y_dev_party,preds2.round()))\n",
        "  print(\"party recall:\",recall_score(y_dev_party,preds2.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_party,preds2)\n",
        "  print(\"party precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755947 training rows\n",
            "Responses include only the first 20 and last 20 words\n",
            "Getting labels\n",
            "training set:\n",
            "M: 2752041, W: 1003906, percent M: 0.7327156107367863\n",
            "dev set:\n",
            "M: 1821965, W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "R: 2337054, D: 1402563, percent R: 0.6249447470155366\n",
            "dev set:\n",
            "R: 1593280, D: 557512, percent R: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 47 seconds\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 40, 50)            250150    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 40, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 40, 128)           19328     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 40, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 516,007\n",
            "Trainable params: 265,857\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3755947 samples, validate on 2150792 samples\n",
            "Epoch 1/20\n",
            "3755947/3755947 [==============================] - 218s 58us/step - loss: 0.5173 - acc: 0.7647 - val_loss: 0.4300 - val_acc: 0.8482\n",
            "Epoch 2/20\n",
            "3755947/3755947 [==============================] - 212s 57us/step - loss: 0.4855 - acc: 0.7815 - val_loss: 0.4177 - val_acc: 0.8477\n",
            "Epoch 3/20\n",
            "3755947/3755947 [==============================] - 212s 57us/step - loss: 0.4794 - acc: 0.7840 - val_loss: 0.4187 - val_acc: 0.8466\n",
            "Epoch 4/20\n",
            "3755947/3755947 [==============================] - 213s 57us/step - loss: 0.4758 - acc: 0.7853 - val_loss: 0.4164 - val_acc: 0.8470\n",
            "Epoch 5/20\n",
            "3755947/3755947 [==============================] - 212s 56us/step - loss: 0.4734 - acc: 0.7862 - val_loss: 0.4342 - val_acc: 0.8432\n",
            "Epoch 6/20\n",
            "3755947/3755947 [==============================] - 212s 57us/step - loss: 0.4715 - acc: 0.7869 - val_loss: 0.4251 - val_acc: 0.8428\n",
            "Epoch 7/20\n",
            "3755947/3755947 [==============================] - 212s 56us/step - loss: 0.4698 - acc: 0.7876 - val_loss: 0.4275 - val_acc: 0.8448\n",
            "Epoch 8/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4683 - acc: 0.7881 - val_loss: 0.4285 - val_acc: 0.8432\n",
            "Epoch 9/20\n",
            "3755947/3755947 [==============================] - 210s 56us/step - loss: 0.4672 - acc: 0.7886 - val_loss: 0.4191 - val_acc: 0.8464\n",
            "Epoch 10/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4663 - acc: 0.7888 - val_loss: 0.4223 - val_acc: 0.8448\n",
            "Epoch 11/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4655 - acc: 0.7893 - val_loss: 0.4196 - val_acc: 0.8451\n",
            "Epoch 12/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4648 - acc: 0.7895 - val_loss: 0.4229 - val_acc: 0.8443\n",
            "Epoch 13/20\n",
            "3755947/3755947 [==============================] - 213s 57us/step - loss: 0.4640 - acc: 0.7898 - val_loss: 0.4397 - val_acc: 0.8402\n",
            "Epoch 14/20\n",
            "3755947/3755947 [==============================] - 213s 57us/step - loss: 0.4634 - acc: 0.7900 - val_loss: 0.4306 - val_acc: 0.8429\n",
            "Epoch 15/20\n",
            "3755947/3755947 [==============================] - 212s 56us/step - loss: 0.4628 - acc: 0.7903 - val_loss: 0.4262 - val_acc: 0.8445\n",
            "Epoch 16/20\n",
            "3755947/3755947 [==============================] - 212s 57us/step - loss: 0.4624 - acc: 0.7904 - val_loss: 0.4329 - val_acc: 0.8383\n",
            "Epoch 17/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4618 - acc: 0.7908 - val_loss: 0.4358 - val_acc: 0.8383\n",
            "Epoch 18/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4612 - acc: 0.7910 - val_loss: 0.4309 - val_acc: 0.8430\n",
            "Epoch 19/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4607 - acc: 0.7911 - val_loss: 0.4251 - val_acc: 0.8437\n",
            "Epoch 20/20\n",
            "3755947/3755947 [==============================] - 211s 56us/step - loss: 0.4604 - acc: 0.7912 - val_loss: 0.4239 - val_acc: 0.8443\n",
            "Trained in 10 minutes, 40 seconds\n",
            "Copying file:///content/Mon_11_25_johnson2_model_0_gender_1574704316.0792446.h5 [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  4.1 MiB/  4.1 MiB]                                                \n",
            "Operation completed over 1 objects/4.1 MiB.                                      \n",
            "Proportion of predictions for W class: 0.04161536773430439\n",
            "gender ROC_AUC: 0.67949438085802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhGRJKdEICKS5JQIRESSnBKBiEiS+38Rilt2Wj8ppwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "gender precision: 0.4658793823877729\n",
            "gender recall: 0.12681136281388086\n",
            "gender precision-recall AUC: 0.30839600409222717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxJwSgYhIzCkRiIjEnBKBiEjM/X9HnA8anTrf0gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739617 samples, validate on 2150792 samples\n",
            "Epoch 1/20\n",
            "1330000/3739617 [=========>....................] - ETA: 1:59 - loss: 0.6448 - acc: 0.6339"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}