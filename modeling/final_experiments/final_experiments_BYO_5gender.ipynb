{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_experiments_BYO_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/final_experiments_BYO_5gender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQFENKGqCqlR",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"Mon11_25_BYO5_idx43\"\n",
        "\n",
        "hyp_combos = [{'ARCHITECTURE': 'BYO',\n",
        "                'NUM_EPOCHS': 30,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128,128],\n",
        "                'FILTER_SIZES': [3,3],\n",
        "                'DROPOUT_RATES': [.2,.2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyp1cqW7BHY",
        "colab_type": "code",
        "outputId": "58229304-8534-4c77-e3b0-dc1fe77f5425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# examples of all the hyp dicts for each arch\n",
        "{'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "{'ARCHITECTURE': 'JOHNSON',\n",
        "                 'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 15,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "{'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 64,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'KIM',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZE': 64,\n",
              "  'DROPOUT_RATE': 0.2,\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [2, 4, 6],\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 10,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "outputId": "13e727b8-547b-4768-bef2-da58da5dee05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "outputId": "34a0dd2a-811f-4a33-ae92-2c843c26c0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, roc_curve, roc_auc_score, precision_recall_curve, auc\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/65/e2/05f903ce8f77804127195cfcc1ca8b500a3157a1572dcc4b82bf5af01564/gcsfs-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.4.0\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "8a3e2a9b-a4d4-45bb-d38b-1aa0ad6d388d"
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "- [4 files][  2.1 GiB/  2.1 GiB]   50.3 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "/ [5 files][  2.9 GiB/  2.9 GiB]   29.8 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    female = sum(final_list)\n",
        "    male = len(final_list)-sum(final_list)\n",
        "    percent_M = male/len(final_list)\n",
        "    print('M: {}, W: {}, percent M: {}'.format(male,female,percent_M))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    democrat = sum(final_list)\n",
        "    republican = len(final_list)-sum(final_list)\n",
        "    percent_repub = republican/len(final_list)\n",
        "    print('R: {}, D: {}, percent R: {}'.format(republican,democrat,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'W'\n",
        "  else:\n",
        "    return 'M'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Democrat'\n",
        "  else:\n",
        "    return 'Congress_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes,\n",
        "                   dropout_rate):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(dropout_rate)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'],\n",
        "                           hyp_dict['DROPOUT_RATE'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50cd8d38-39b5-4f51-d907-c914ad4f6005"
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_gender,preds)\n",
        "  print(\"gender ROC_AUC:\",roc_auc_score(y_dev_gender,preds))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"gender precision:\",precision_score(y_dev_gender,preds.round()))\n",
        "  print(\"gender recall:\",recall_score(y_dev_gender,preds.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_gender,preds)\n",
        "  print(\"gender precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Democrat' in dev_df.preds2.value_counts():\n",
        "    proportion_dem_predicted = dev_df.preds2.value_counts()['Congress_Democrat'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_dem_predicted = 0\n",
        "  print(\"Proportion of predictions for Democrat class: {}\".format(proportion_dem_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_party,preds2)\n",
        "  print(\"party ROC_AUC:\",roc_auc_score(y_dev_party,preds2))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"party precision:\",precision_score(y_dev_party,preds2.round()))\n",
        "  print(\"party recall:\",recall_score(y_dev_party,preds2.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_party,preds2)\n",
        "  print(\"party precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755947 training rows\n",
            "Responses include only the first 10 and last 10 words\n",
            "Getting labels\n",
            "training set:\n",
            "M: 2752041, W: 1003906, percent M: 0.7327156107367863\n",
            "dev set:\n",
            "M: 1821965, W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "R: 2337054, D: 1402563, percent R: 0.6249447470155366\n",
            "dev set:\n",
            "R: 1593280, D: 557512, percent R: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 20 seconds\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 50)            250150    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 20, 128)           19328     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 20, 128)           49280     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 320,059\n",
            "Trainable params: 69,909\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3755947 samples, validate on 2150792 samples\n",
            "Epoch 1/30\n",
            "3755947/3755947 [==============================] - 155s 41us/step - loss: 0.5001 - acc: 0.7752 - val_loss: 0.4546 - val_acc: 0.8455\n",
            "Epoch 2/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4810 - acc: 0.7832 - val_loss: 0.4448 - val_acc: 0.8471\n",
            "Epoch 3/30\n",
            "3755947/3755947 [==============================] - 160s 43us/step - loss: 0.4768 - acc: 0.7849 - val_loss: 0.4434 - val_acc: 0.8466\n",
            "Epoch 4/30\n",
            "3755947/3755947 [==============================] - 164s 44us/step - loss: 0.4749 - acc: 0.7855 - val_loss: 0.4379 - val_acc: 0.8446\n",
            "Epoch 5/30\n",
            "3755947/3755947 [==============================] - 164s 44us/step - loss: 0.4735 - acc: 0.7859 - val_loss: 0.4329 - val_acc: 0.8471\n",
            "Epoch 6/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4726 - acc: 0.7862 - val_loss: 0.4371 - val_acc: 0.8458\n",
            "Epoch 7/30\n",
            "3755947/3755947 [==============================] - 161s 43us/step - loss: 0.4718 - acc: 0.7866 - val_loss: 0.4371 - val_acc: 0.8451\n",
            "Epoch 8/30\n",
            "3755947/3755947 [==============================] - 156s 41us/step - loss: 0.4712 - acc: 0.7868 - val_loss: 0.4346 - val_acc: 0.8470\n",
            "Epoch 9/30\n",
            "3755947/3755947 [==============================] - 156s 42us/step - loss: 0.4707 - acc: 0.7869 - val_loss: 0.4314 - val_acc: 0.8473\n",
            "Epoch 10/30\n",
            "3755947/3755947 [==============================] - 154s 41us/step - loss: 0.4702 - acc: 0.7872 - val_loss: 0.4325 - val_acc: 0.8459\n",
            "Epoch 11/30\n",
            "3755947/3755947 [==============================] - 157s 42us/step - loss: 0.4698 - acc: 0.7873 - val_loss: 0.4357 - val_acc: 0.8441\n",
            "Epoch 12/30\n",
            "3755947/3755947 [==============================] - 158s 42us/step - loss: 0.4695 - acc: 0.7874 - val_loss: 0.4408 - val_acc: 0.8456\n",
            "Epoch 13/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4692 - acc: 0.7876 - val_loss: 0.4359 - val_acc: 0.8443\n",
            "Epoch 14/30\n",
            "3755947/3755947 [==============================] - 158s 42us/step - loss: 0.4689 - acc: 0.7877 - val_loss: 0.4369 - val_acc: 0.8456\n",
            "Epoch 15/30\n",
            "3755947/3755947 [==============================] - 161s 43us/step - loss: 0.4685 - acc: 0.7877 - val_loss: 0.4301 - val_acc: 0.8466\n",
            "Epoch 16/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4683 - acc: 0.7878 - val_loss: 0.4353 - val_acc: 0.8447\n",
            "Epoch 17/30\n",
            "3755947/3755947 [==============================] - 157s 42us/step - loss: 0.4681 - acc: 0.7878 - val_loss: 0.4276 - val_acc: 0.8462\n",
            "Epoch 18/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4679 - acc: 0.7880 - val_loss: 0.4315 - val_acc: 0.8459\n",
            "Epoch 19/30\n",
            "3755947/3755947 [==============================] - 161s 43us/step - loss: 0.4677 - acc: 0.7881 - val_loss: 0.4377 - val_acc: 0.8459\n",
            "Epoch 20/30\n",
            "3755947/3755947 [==============================] - 158s 42us/step - loss: 0.4676 - acc: 0.7880 - val_loss: 0.4359 - val_acc: 0.8454\n",
            "Epoch 21/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4674 - acc: 0.7880 - val_loss: 0.4330 - val_acc: 0.8465\n",
            "Epoch 22/30\n",
            "3755947/3755947 [==============================] - 156s 42us/step - loss: 0.4672 - acc: 0.7881 - val_loss: 0.4357 - val_acc: 0.8446\n",
            "Epoch 23/30\n",
            "3755947/3755947 [==============================] - 158s 42us/step - loss: 0.4670 - acc: 0.7883 - val_loss: 0.4326 - val_acc: 0.8460\n",
            "Epoch 24/30\n",
            "3755947/3755947 [==============================] - 155s 41us/step - loss: 0.4668 - acc: 0.7883 - val_loss: 0.4336 - val_acc: 0.8456\n",
            "Epoch 25/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4666 - acc: 0.7884 - val_loss: 0.4374 - val_acc: 0.8445\n",
            "Epoch 26/30\n",
            "3755947/3755947 [==============================] - 156s 42us/step - loss: 0.4666 - acc: 0.7883 - val_loss: 0.4374 - val_acc: 0.8454\n",
            "Epoch 27/30\n",
            "3755947/3755947 [==============================] - 159s 42us/step - loss: 0.4666 - acc: 0.7883 - val_loss: 0.4368 - val_acc: 0.8450\n",
            "Epoch 28/30\n",
            "3755947/3755947 [==============================] - 158s 42us/step - loss: 0.4662 - acc: 0.7885 - val_loss: 0.4339 - val_acc: 0.8454\n",
            "Epoch 29/30\n",
            "3755947/3755947 [==============================] - 161s 43us/step - loss: 0.4662 - acc: 0.7886 - val_loss: 0.4376 - val_acc: 0.8439\n",
            "Epoch 30/30\n",
            "3755947/3755947 [==============================] - 155s 41us/step - loss: 0.4661 - acc: 0.7886 - val_loss: 0.4333 - val_acc: 0.8457\n",
            "Trained in 19 minutes, 11 seconds\n",
            "Copying file:///content/Mon11_25_BYO5_idx43_model_0_gender_1574711338.200589.h5 [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.8 MiB/  1.8 MiB]                                                \n",
            "Operation completed over 1 objects/1.8 MiB.                                      \n",
            "Proportion of predictions for W class: 0.024031612540868667\n",
            "gender ROC_AUC: 0.6625455996953221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIglOiUBEJMEpEYiIJDglAhGRBPf/sESMWS4c1pkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "gender precision: 0.4712403505717105\n",
            "gender recall: 0.07407238456696075\n",
            "gender precision-recall AUC: 0.27978949564166017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfH0lEQVR4nO3dfZwdVZ3n8c+XBCTyDMEeSCKBMaiR\nrAo9EHWdbYiGBh/CuqgwSAIbySigM2N2NM7DgiAr7oiM+IBEiUlcFLOok4wGMxngDuoaCAxIDMjQ\nQiAJgQiBQIOCwd/+Uedi5XJP900/3NsP3/fr1a+uOnVOnXOqqutXz62IwMzMrJ7dWt0AMzMbuhwk\nzMwsy0HCzMyyHCTMzCzLQcLMzLIcJMzMLMtBYpiSdKGk/9PHsmdJ+kkP0yuSPpiGz5D0Lz3kfauk\ne/vSjl7a+GFJj0rqlnTQQM9/sPW2jIcaSSHpVWn4q5L+vo/z6ZZ0xMC2rjl2ZZ1JWizp04PdpqHA\nQaKJJG2Q9Jv0h/Ro2tD2bnW7ehIR10TEzOp4eWeSpv84Il49kHVK2h34PDAzIvaOiMcHaL6nSbpF\n0jOStqbhcyVpIOY/mFLg/m3adh6T9D1JhwxGXRHxoYi4uME2fbCm7N4Rcf9gtKtU7+S0Hd5Rkz5e\n0vOSNgxm/Y2Q9GeSHkzb2j9JOrDVbeorB4nme1dE7A0cDbQDf1ebQYXRvG7agD2B9btaMLfsJM0H\nvgD8A/BHqY4PAW8B9uhXaweYpDGZSeenbedIYH/g8l0sP9K8XNJRpfE/Ax5oVWOqJL0OuAo4k2I7\nexb4Sksb1Q+jeUfUUhGxGbgeOApePCq7RNJPKTaqIyQdKmmFpG2SuiSdUzObPSV9R9LTkv5d0uur\nEyQtkPSrNO1uSf+1pqwkfUnSdkm/lDSjXjvLp+CSbk7JP09HtO+X1CFpUyn/oZK+K+nXkh6Q9NHS\ntGMl3SbpqXQm9fk69R0JVC9fPSnpxpT+ZklrU3vXSnpzqcxLll3NPPcDLgLOjYjrIuLpKNwREWdE\nxHMp38skfU7SQ6l9X5U0Lk3rkLRJ0vx0FrJF0tmlOg5K6+opSbcCf1zThtdIWp3W5b2S3leatljS\nlZJWSnoGOL7euqiKiG3Ad/nDtvOS8j31JZX569SHhyX995q27nQpRdIsSXemvv1KUqekS4C3Al9K\n28KXUt7yZav9JC1N28KDkv6uGsCr21Vq4xNpWzmpp37X8U1gTml8NrC0pi+vTdvHk5LWS3p3aVqf\n11kvzgD+OSJujohu4O+B90jaZxf7NzREhH+a9ANsAN6WhidRHClfnMYrwEPA64CxwO7AzRRHIHsC\nbwB+DZyQ8l8I/A44NeX9HxRHUbun6e8FDqU4EHg/8AxwSJp2FrAD+KtU9v3AduDAUls+WMr7k1If\nAnhVabwD2JSGdwNuB/4nxdH5EcD9wIlp+s+AM9Pw3sD0zHKanOoZm8YPBJ6gODIbC5yexg/KLbua\n+XWm/o7tZf1cDqxI9e0D/DPwmVI/d1AEm92BkykC0gFp+rXAMmAvip335upyS2kbgbNT+94IPAZM\nTdMXp+X/lrQM96zTtvI6GQ/cCHwzV76XvnQCj6Z27gV8q7xe0/w+nYaPTfN+e5r3BOA1tW2qt31Q\n7LCXp/onA/8BzC1tV78DzgHGAB8GHgbUwN9RdfuYnJbrGGAq8EvgbcCGlG93oAv4G4rt8QTgaeDV\nA7TOPp1p33LgEzVp3cAxrd4H9Wm/1eoGjKYfiiDRDTwJPEgRAMalaRXgolLeScALwD6ltM8Ai9Pw\nhcCa0rTdgC3AWzN13wnMSsNn1f5BArfyhx34i3/87FqQOA54qKbeTwLfSMM3A58CxveynKo7gWqQ\nOBO4tSbPz4Cz6i27OvP7APBITdr/S+vhN8CfAqIIpH9cyvMm4IFSP39DKdAAW4HpFDup35F2nmna\n/yrtcN4P/Lim/quAC9LwYmBpL8ukQhGUnqTYmV0DHFyvfAN9WQRcWpp2JPkgcRVweQ9tqhsk0jJ5\nnrRTTdP+HKiUtquu0rSXp7J/1MDf0YvbB/CvwInApcDfsnOQeCvwCLBbqey3Kf52BmKd5YLEDcCH\natI2Ax299W0o/ozFmu2UiPjXzLSNpeFDgW0R8XQp7UGK+xgvyR8Rv0+XfQ4FkDQb+BjFHxQUR+7j\nS2U3R9p6S/M+dBf6Uc9hwKGSniyljQF+nIbnUhyJ/1LSA8CnIuIHDcz30NS+sgcpjmqrNpL3ODBe\n0tiI2AEQEW8GSMtsN+Bgih3V7frDfWyl9r84n2r55FmK5XowxQ6r3IZyew8DjqtZLmMpLpc00v6q\nj0bE1zPTyuV768uhFGd89dpaaxKwsoG21RpPcSRfnnftOnukOhARz6a27uqDHEspAs6bKYLCkaVp\nhwIbI+L3ddowEOsspxvYtyZtX4qzmGHHQWJoKe+0HwYOlLRPKVC8kuKIpGpSdSBd650IPCzpMOBr\nwAzgZxHxgqQ7KXYUVRMkqRQoXklxeaI/NlIcrU6pNzEi7gNOT219D3CdpIMi4ple5vswxR9t2SuB\nH5Vn30P5nwHPAbMoruXX8xjFmcLrorhftCt+TXEpahLFJY9q+6o2Av8WEW/vYR79/RxzuXxvfdlC\nadth57bW2kjNtfpMnbUeozhSPwy4u1TPri7b3nwX+BJwe0Q8lO5pVT0MTJK0WylQvJListdArLOc\n9UD5/uARwMtSvcOOb1wPURGxkeKSyGck7SnpP1EciZffjThG0nskjQX+kmJHuIbiempQ/CGQbrCW\nnwIBeAXwUUm7S3ov8FoaO2J8lJobwyW3Ak9L+oSkcZLGSDpK0p+kdnxA0sHpD7Z6hPb7zLzKVgJH\nqniscKyk91Ncg27kLISIeJLiMtdXJJ0qaR9Ju0l6A8WyIrXpa8Dlkl6R2jtB0okNzP8F4HvAhZJe\nLmkqO99Q/UFq/5lpee8u6U8kvbaR9u+qBvqyDDhL0lRJLwcu6GF2VwNnS5qRltkESa9J07LbQlom\ny4BL0vI+jOLMtqF3e1S8B1TpLV86wDgB+GCdybdQnO19PC3zDuBdwLWDvM6uAd6l4h2ivSjOnr9X\nc1Vg2HCQGNpOp7hc9DDwfYrroeVLVcsprp1Wb+q+JyJ+FxF3A5dRHEE/CkwDfloz71uAKRRHfJcA\np0Zj7yNcCCxJT4vs9LRH+sN7J8VN9gfSvL8O7JeydALrJXVTPI56WkT8prcKU7veCcynuHT0ceCd\nEfFYA+2tzuN/U+ykPk6xTB6luMb8CYpgTBruAtZIeorienej74CcT3Gp5BGK69XfKNX9NDATOI1i\nXT4CfJbi6HKwZPsSEdcD/0hx87sr/a4rIm6luHl7OcUN7H/jD2d1XwBOTU8nXVGn+Eco7o3cD/yE\n4gb5ogbbP4mXbrO5Nt4WEb+qk/48RVA4iWJb/AowOyKqZw6Dss4iYj3F49XXUNy32gc4t5G+DEXa\n+bK0mVnrpcujMxo8cLFB5CBhZmZZvtxkZmZZDQUJSftLuk7Fm7n3SHqTpAPT24j3pd8HpLySdIWK\nN4TvknR0aT5zUv77JM0ppR8jaV0qc4XSs3C5OszMrDkaPZP4AvCjiHgNxaNd9wALgBvS4443pHEo\nbhJNST/zgCuh2OFTPEVxHMVbnBeUdvpXUrx5WS3XmdJzdZiZWRP0ek9CxXdv7gSOKL98peLz0B0R\nsUXF1ygrEfFqSVel4W+X81V/IuLPU/pVFG9sVoCbUgBC0unVfLk6emrv+PHjY/Lkybu2FJJnnnmG\nvfbaq09lhyv3eXRwn0e+/vb39ttvfywiDq5Nb+RlusMpnrf/hooPyN0O/AXQFhFbUp5HKL52CMXb\njOW3GDeltJ7SN9VJp4c6diJpHsVZC21tbXzuc59roFsv1d3dzd57D+kvdw8493l0cJ9Hvv729/jj\nj6/75n0jQWIsxWetPxIRt0j6AjWXfSIiJA3qY1I91RERC4GFAO3t7dHR0dGnOiqVCn0tO1y5z6OD\n+zzyDVZ/G7knsYniA263pPHrKILGo+kSEOn31jR9Mzu/8j8xpfWUPrFOOj3UYWZmTdBrkIiIR4CN\nkqr3AmZQfItlBX94jX0Oxdu/pPTZ6Smn6cD2dMloFTBT0gHphvVMYFWa9pSk6empptk186pXh5mZ\nNUGjH/j7CHCNpD0oXrE/myLALJM0l+LridVPNKyk+NZ+F8V3U86G4h+lSLoYWJvyXRTFP0+B4pX1\nxcA4in/Ec31KvzRTh5mZNUFDQSIi7mTnT1RXveS/maUnoM7LzGcRdb7dEhG38dIP0FW/2VP3P6aZ\nmdng8xvXZmaW5SBhZmZZDhJmZpblIGFmZln+96Wj3LrN2zlrwQ/7VHbDpe8Y4NaY2VDjIGF9NrmP\nwQUcYMyGC19uMjOzLAcJMzPLcpAwM7MsBwkzM8tykDAzsywHCTMzy3KQMDOzLAcJMzPLcpAwM7Ms\nBwkzM8tykDAzsywHCTMzy3KQMDOzLAcJMzPLcpAwM7MsBwkzM8tykDAzsywHCTMzy3KQMDOzLAcJ\nMzPLcpAwM7OshoKEpA2S1km6U9JtKe1ASasl3Zd+H5DSJekKSV2S7pJ0dGk+c1L++yTNKaUfk+bf\nlcqqpzrMzKw5duVM4viIeENEtKfxBcANETEFuCGNA5wETEk/84ArodjhAxcAxwHHAheUdvpXAueU\nynX2UoeZmTVBfy43zQKWpOElwCml9KVRWAPsL+kQ4ERgdURsi4gngNVAZ5q2b0SsiYgAltbMq14d\nZmbWBGMbzBfAv0gK4KqIWAi0RcSWNP0RoC0NTwA2lspuSmk9pW+qk04PdexE0jyKsxba2tqoVCoN\ndmtn3d3dfS47XLWNg/nTdjS93lYu59G4nt3nkW+w+ttokPjPEbFZ0iuA1ZJ+WZ4YEZECyKDpqY4U\ntBYCtLe3R0dHR5/qqFQq9LXscPXFa5Zz2bpGN4OBs+GMjqbXWTUa17P7PPINVn8butwUEZvT763A\n9ynuKTyaLhWRfm9N2TcDk0rFJ6a0ntIn1kmnhzrMzKwJeg0SkvaStE91GJgJ/AJYAVSfUJoDLE/D\nK4DZ6Smn6cD2dMloFTBT0gHphvVMYFWa9pSk6empptk186pXh5mZNUEj1xnagO+np1LHAt+KiB9J\nWgsskzQXeBB4X8q/EjgZ6AKeBc4GiIhtki4G1qZ8F0XEtjR8LrAYGAdcn34ALs3UYWZmTdBrkIiI\n+4HX10l/HJhRJz2A8zLzWgQsqpN+G3BUo3WYmVlz+I1rMzPLcpAwM7MsBwkzM8tykDAzsywHCTMz\ny3KQMDOzLAcJMzPLcpAwM7MsBwkzM8tykDAzsywHCTMzy3KQMDOzLAcJMzPLcpAwM7MsBwkzM8ty\nkDAzsywHCTMzy3KQMDOzLAcJMzPLcpAwM7MsBwkzM8tykDAzsywHCTMzy3KQMDOzLAcJMzPLcpAw\nM7MsBwkzM8tqOEhIGiPpDkk/SOOHS7pFUpek70jaI6W/LI13pemTS/P4ZEq/V9KJpfTOlNYlaUEp\nvW4dZmbWHLtyJvEXwD2l8c8Cl0fEq4AngLkpfS7wREq/POVD0lTgNOB1QCfwlRR4xgBfBk4CpgKn\np7w91WFmZk3QUJCQNBF4B/D1NC7gBOC6lGUJcEoanpXGSdNnpPyzgGsj4rmIeADoAo5NP10RcX9E\nPA9cC8zqpQ4zM2uCsQ3m+0fg48A+afwg4MmI2JHGNwET0vAEYCNAROyQtD3lnwCsKc2zXGZjTfpx\nvdSxE0nzgHkAbW1tVCqVBru1s+7u7j6XHa7axsH8aTt6zzjAWrmcR+N6dp9HvsHqb69BQtI7ga0R\ncbukjgFvwQCIiIXAQoD29vbo6Ojo03wqlQp9LTtcffGa5Vy2rtFjhYGz4YyOptdZNRrXs/s88g1W\nfxvZO7wFeLekk4E9gX2BLwD7SxqbjvQnAptT/s3AJGCTpLHAfsDjpfSqcpl66Y/3UIeZmTVBr/ck\nIuKTETExIiZT3Hi+MSLOAG4CTk3Z5gDL0/CKNE6afmNEREo/LT39dDgwBbgVWAtMSU8y7ZHqWJHK\n5OowM7Mm6M97Ep8APiapi+L+wdUp/WrgoJT+MWABQESsB5YBdwM/As6LiBfSWcL5wCqKp6eWpbw9\n1WFmZk2wSxejI6ICVNLw/RRPJtXm+S3w3kz5S4BL6qSvBFbWSa9bh5mZNYffuDYzsywHCTMzy3KQ\nMDOzLAcJMzPLcpAwM7MsBwkzM8tykDAzsywHCTMzy3KQMDOzLAcJMzPLcpAwM7MsBwkzM8tykDAz\nsywHCTMzy3KQMDOzLAcJMzPLcpAwM7MsBwkzM8tykDAzsywHCTMzy3KQMDOzLAcJMzPLcpAwM7Ms\nBwkzM8tykDAzsywHCTMzy3KQMDOzrF6DhKQ9Jd0q6eeS1kv6VEo/XNItkrokfUfSHin9ZWm8K02f\nXJrXJ1P6vZJOLKV3prQuSQtK6XXrMDOz5mjkTOI54ISIeD3wBqBT0nTgs8DlEfEq4Algbso/F3gi\npV+e8iFpKnAa8DqgE/iKpDGSxgBfBk4CpgKnp7z0UIeZmTVBr0EiCt1pdPf0E8AJwHUpfQlwShqe\nlcZJ02dIUkq/NiKei4gHgC7g2PTTFRH3R8TzwLXArFQmV4eZmTXB2EYypaP924FXURz1/wp4MiJ2\npCybgAlpeAKwESAidkjaDhyU0teUZlsus7Em/bhUJldHbfvmAfMA2traqFQqjXTrJbq7u/tcdrhq\nGwfzp+3oPeMAa+VyHo3r2X0e+Qarvw0FiYh4AXiDpP2B7wOvGfCW9ENELAQWArS3t0dHR0ef5lOp\nVOhr2eHqi9cs57J1DW0GA2rDGR1Nr7NqNK5n93nkG6z+7tLTTRHxJHAT8CZgf0nVvctEYHMa3gxM\nAkjT9wMeL6fXlMmlP95DHWZm1gSNPN10cDqDQNI44O3APRTB4tSUbQ6wPA2vSOOk6TdGRKT009LT\nT4cDU4BbgbXAlPQk0x4UN7dXpDK5OszMrAkauc5wCLAk3ZfYDVgWET+QdDdwraRPA3cAV6f8VwPf\nlNQFbKPY6RMR6yUtA+4GdgDnpctYSDofWAWMARZFxPo0r09k6jAzsyboNUhExF3AG+uk30/xZFJt\n+m+B92bmdQlwSZ30lcDKRuswM7Pm8BvXZmaW1fzHWmzATV7wwz6XnT9tABtiZiOOzyTMzCzLQcLM\nzLIcJMzMLMtBwszMshwkzMwsy0HCzMyyHCTMzCzL70lYS/Tn3Q6ADZe+Y4BaYmY98ZmEmZllOUiY\nmVmWg4SZmWU5SJiZWZaDhJmZZTlImJlZloOEmZllOUiYmVmWg4SZmWU5SJiZWZaDhJmZZTlImJlZ\nloOEmZllOUiYmVmWg4SZmWU5SJiZWZaDhJmZZfUaJCRNknSTpLslrZf0Fyn9QEmrJd2Xfh+Q0iXp\nCkldku6SdHRpXnNS/vskzSmlHyNpXSpzhST1VIeZmTVHI2cSO4D5ETEVmA6cJ2kqsAC4ISKmADek\ncYCTgCnpZx5wJRQ7fOAC4DjgWOCC0k7/SuCcUrnOlJ6rw8zMmqDXIBERWyLi39Pw08A9wARgFrAk\nZVsCnJKGZwFLo7AG2F/SIcCJwOqI2BYRTwCrgc40bd+IWBMRASytmVe9OszMrAl26Z6EpMnAG4Fb\ngLaI2JImPQK0peEJwMZSsU0praf0TXXS6aEOMzNrgrGNZpS0N/Bd4C8j4ql02wCAiAhJMQjta6gO\nSfMoLm3R1tZGpVLpUx3d3d19LttK86ft6HPZtnH9K98q/VlPw3U994f7PPINVn8bChKSdqcIENdE\nxPdS8qOSDomILemS0daUvhmYVCo+MaVtBjpq0ispfWKd/D3VsZOIWAgsBGhvb4+Ojo562XpVqVTo\na9lWOmvBD/tcdv60HVy2ruFjhSFjwxkdfS47XNdzf7jPI99g9beRp5sEXA3cExGfL01aAVSfUJoD\nLC+lz05POU0HtqdLRquAmZIOSDesZwKr0rSnJE1Pdc2umVe9OszMrAkaOYR8C3AmsE7SnSntb4BL\ngWWS5gIPAu9L01YCJwNdwLPA2QARsU3SxcDalO+iiNiWhs8FFgPjgOvTDz3UYWZmTdBrkIiInwDK\nTJ5RJ38A52XmtQhYVCf9NuCoOumP16vDzMyaw29cm5lZloOEmZllOUiYmVmWg4SZmWU5SJiZWZaD\nhJmZZTlImJlZloOEmZllOUiYmVmWg4SZmWU5SJiZWZaDhJmZZTlImJlZloOEmZllOUiYmVmWg4SZ\nmWU5SJiZWZaDhJmZZTlImJlZloOEmZllOUiYmVmWg4SZmWWNbXUDDCYv+GGrm2BmVpfPJMzMLMtB\nwszMshwkzMwsy0HCzMyyHCTMzCyr1yAhaZGkrZJ+UUo7UNJqSfel3wekdEm6QlKXpLskHV0qMyfl\nv0/SnFL6MZLWpTJXSFJPdZiZWfM0ciaxGOisSVsA3BARU4Ab0jjAScCU9DMPuBKKHT5wAXAccCxw\nQWmnfyVwTqlcZy91mJlZk/QaJCLiZmBbTfIsYEkaXgKcUkpfGoU1wP6SDgFOBFZHxLaIeAJYDXSm\naftGxJqICGBpzbzq1WFmZk3S15fp2iJiSxp+BGhLwxOAjaV8m1JaT+mb6qT3VMdLSJpHceZCW1sb\nlUplF7tT6O7u7nPZ/pg/bUfT66xqG9fa+vuqP+upVeu5ldznkW+w+tvvN64jIiTFQDSmr3VExEJg\nIUB7e3t0dHT0qZ5KpUJfy/bHWS1843r+tB1ctm74vXi/4YyOPpdt1XpuJfd55Bus/vb16aZH06Ui\n0u+tKX0zMKmUb2JK6yl9Yp30nuowM7Mm6WuQWAFUn1CaAywvpc9OTzlNB7anS0argJmSDkg3rGcC\nq9K0pyRNT081za6ZV706zMysSXq9ziDp20AHMF7SJoqnlC4FlkmaCzwIvC9lXwmcDHQBzwJnA0TE\nNkkXA2tTvosionoz/FyKJ6jGAdenH3qow8zMmqTXIBERp2cmzaiTN4DzMvNZBCyqk34bcFSd9Mfr\n1WEG/fty7uLOvQawJWYjm9+4NjOzLAcJMzPLcpAwM7MsBwkzM8tykDAzs6zh96rtIFq3eXtL3342\nMxtqfCZhZmZZDhJmZpblIGFmZlkOEmZmluUgYWZmWQ4SZmaW5SBhZmZZDhJmZpblIGFmZll+49pG\nnf68Wb/h0ncMcGvMhjafSZiZWZaDhJmZZTlImJlZloOEmZllOUiYmVmWn24y2wWT+/H/RvxklA1H\nPpMwM7MsBwkzM8vy5SazJvGlKhuOfCZhZmZZPpMwGwb6cxYCsLhzrwFqiY02Q/5MQlKnpHsldUla\n0Or2mJmNJkP6TELSGODLwNuBTcBaSSsi4u7WtsxseOnPRw37w/dSdk1/zhgH62xxSAcJ4FigKyLu\nB5B0LTALcJAwGwb6e5msP+ZP29GSwDjSKCJa3YYsSacCnRHxwTR+JnBcRJxfk28eMC+Nvhq4t49V\njgce62PZ4cp9Hh3c55Gvv/09LCIOrk0c6mcSDYmIhcDC/s5H0m0R0T4ATRo23OfRwX0e+Qarv0P9\nxvVmYFJpfGJKMzOzJhjqQWItMEXS4ZL2AE4DVrS4TWZmo8aQvtwUETsknQ+sAsYAiyJi/SBW2e9L\nVsOQ+zw6uM8j36D0d0jfuDYzs9Ya6pebzMyshRwkzMwsa1QGid4+9SHpZZK+k6bfImly81s5sBro\n88ck3S3pLkk3SDqsFe0cSI1+0kXSf5MUkob145KN9FfS+9J6Xi/pW81u40BrYLt+paSbJN2Rtu2T\nW9HOgSRpkaStkn6RmS5JV6Rlcpeko/tVYUSMqh+KG+C/Ao4A9gB+DkytyXMu8NU0fBrwnVa3uwl9\nPh54eRr+8Gjoc8q3D3AzsAZob3W7B3kdTwHuAA5I469odbub0OeFwIfT8FRgQ6vbPQD9/lPgaOAX\nmeknA9cDAqYDt/SnvtF4JvHipz4i4nmg+qmPslnAkjR8HTBDkprYxoHWa58j4qaIeDaNrqF4J2U4\na2Q9A1wMfBb4bTMbNwga6e85wJcj4gmAiNja5DYOtEb6HMC+aXg/4OEmtm9QRMTNwLYesswClkZh\nDbC/pEP6Wt9oDBITgI2l8U0prW6eiNgBbAcOakrrBkcjfS6bS3EkMpz12ud0Gj4pIkbCB34aWcdH\nAkdK+qmkNZI6m9a6wdFIny8EPiBpE7AS+EhzmtZSu/r33qMh/Z6ENZ+kDwDtwH9pdVsGk6TdgM8D\nZ7W4Kc00luKSUwfFmeLNkqZFxJMtbdXgOh1YHBGXSXoT8E1JR0XE71vdsOFiNJ5JNPKpjxfzSBpL\ncZr6eFNaNzga+ryJpLcBfwu8OyKea1LbBktvfd4HOAqoSNpAce12xTC+ed3IOt4ErIiI30XEA8B/\nUASN4aqRPs8FlgFExM+APSk+hDeSDejnjEZjkGjkUx8rgDlp+FTgxkh3hIapXvss6Y3AVRQBYrhf\nq4Ze+hwR2yNifERMjojJFPdh3h0Rt7Wmuf3WyHb9TxRnEUgaT3H56f5mNnKANdLnh4AZAJJeSxEk\nft3UVjbfCmB2esppOrA9Irb0dWaj7nJTZD71Ieki4LaIWAFcTXFa2kVxg+i01rW4/xrs8z8AewP/\nN92jfygi3t2yRvdTg30eMRrs7ypgpqS7gReAv46IYXuG3GCf5wNfk/RXFDexzxrmB3xI+jZFsB+f\n7rVcAOwOEBFfpbj3cjLQBTwLnN2v+ob58jIzs0E0Gi83mZlZgxwkzMwsy0HCzMyyHCTMzCzLQcLM\nzLIcJMzMLMtBwszMsv4/zihSmvtGqKkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739617 samples, validate on 2150792 samples\n",
            "Epoch 1/30\n",
            "2508000/3739617 [===================>..........] - ETA: 55s - loss: 0.5825 - acc: 0.6819Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}