{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "three_plus_word_responses.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/modeling/three_plus_word_responses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldVKPuCY1oqk",
        "colab_type": "text"
      },
      "source": [
        "## Remove posts with only 1 or 2 words. Leave response length at 20.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJtCeCgbSs0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this notebook is based off of this blog post: \n",
        "# https://realpython.com/python-keras-text-classification/#reader-comments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QYIGfoPFRZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_NAME = \"three_plus_words\"\n",
        "MODEL_NAME = \"three_plus_words\"\n",
        "MAX_SEQ_LENGTH = 20\n",
        "TRAINING_SET_SIZE = 4000000\n",
        "VAL_SET_SIZE = 2000000\n",
        "NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 1000\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "\n",
        "\n",
        "# I don't think we have a good reason to do this right now\n",
        "# but we might eventually \n",
        "SAVE_TOKENIZED_DATA = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0rrZSx7Ss0M",
        "colab_type": "code",
        "outputId": "07ad35e5-569f-4aa1-a9dc-458ee1eb29c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/65/e2/05f903ce8f77804127195cfcc1ca8b500a3157a1572dcc4b82bf5af01564/gcsfs-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Collecting fsspec>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/d9/40c970ef234cd3054c9cd6c087b92f24ea5b1209c87dcb931e28a72dbc29/fsspec-0.6.0-py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Installing collected packages: fsspec, gcsfs\n",
            "  Found existing installation: fsspec 0.5.2\n",
            "    Uninstalling fsspec-0.5.2:\n",
            "      Successfully uninstalled fsspec-0.5.2\n",
            "Successfully installed fsspec-0.6.0 gcsfs-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKNfUKrfUgP-",
        "colab_type": "code",
        "outputId": "b3e0b01c-8119-4d44-8d9b-d45b476c5220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "# this cell is only necessary if running in colab\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T7PzdLQSs0j",
        "colab_type": "code",
        "outputId": "d6a48ccc-bb84-495b-ce85-f445f652f7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iOniVLISs0m",
        "colab_type": "code",
        "outputId": "5ac4abd4-e183-41cd-c4a9-b50449446986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sOBM6Q6Q4Mz",
        "colab_type": "code",
        "outputId": "1668328d-4376-4ff1-f380-0cda0b45bd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(dev_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2292907"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwNu4VTq46QG",
        "colab_type": "code",
        "outputId": "73b3f497-a2fd-484d-92e6-15b63cfd7658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# Remove 1 and 2 word responses from training set.\n",
        "# Split response string by spaces.\n",
        "train_df['split_response'] = train_df['response_text'].str.split()\n",
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_idx</th>\n",
              "      <th>op_id</th>\n",
              "      <th>op_gender</th>\n",
              "      <th>post_id</th>\n",
              "      <th>responder_id</th>\n",
              "      <th>response_text</th>\n",
              "      <th>op_name</th>\n",
              "      <th>op_category</th>\n",
              "      <th>split_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>57265377</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>Jerry</td>\n",
              "      <td>protecting birth is not the same as protecting life. you may very well pledge to the former but ...</td>\n",
              "      <td>Roger Williams</td>\n",
              "      <td>Congress_Republican</td>\n",
              "      <td>[protecting, birth, is, not, the, same, as, protecting, life., you, may, very, well, pledge, to,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57265377</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>Andrea</td>\n",
              "      <td>you need to protect children and leave my body to me.</td>\n",
              "      <td>Roger Williams</td>\n",
              "      <td>Congress_Republican</td>\n",
              "      <td>[you, need, to, protect, children, and, leave, my, body, to, me.]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>57265377</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>Sherry</td>\n",
              "      <td>thank you</td>\n",
              "      <td>Roger Williams</td>\n",
              "      <td>Congress_Republican</td>\n",
              "      <td>[thank, you]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>57265377</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>Bob</td>\n",
              "      <td>thank you roger</td>\n",
              "      <td>Roger Williams</td>\n",
              "      <td>Congress_Republican</td>\n",
              "      <td>[thank, you, roger]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>57265377</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>Joy</td>\n",
              "      <td>unwanted pregnancy is a sad and unfortunate situation for anyone to find themselves in, however,...</td>\n",
              "      <td>Roger Williams</td>\n",
              "      <td>Congress_Republican</td>\n",
              "      <td>[unwanted, pregnancy, is, a, sad, and, unfortunate, situation, for, anyone, to, find, themselves...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   original_idx  ...                                                                                       split_response\n",
              "0             0  ...  [protecting, birth, is, not, the, same, as, protecting, life., you, may, very, well, pledge, to,...\n",
              "1             1  ...                                    [you, need, to, protect, children, and, leave, my, body, to, me.]\n",
              "2             2  ...                                                                                         [thank, you]\n",
              "3             3  ...                                                                                  [thank, you, roger]\n",
              "4             4  ...  [unwanted, pregnancy, is, a, sad, and, unfortunate, situation, for, anyone, to, find, themselves...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk4goOwAPXRH",
        "colab_type": "code",
        "outputId": "095943af-42f6-4519-c89a-84c80998da06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9879016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDZQzI7RNjfW",
        "colab_type": "code",
        "outputId": "c33819ed-73b9-4f50-c9b4-d80e4c75f1d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Remove the split responses that have length 1 or 2.\n",
        "mask = (train_df['split_response'].str.len() > 2) \n",
        "train_df = train_df.loc[mask]\n",
        "len(train_df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8685575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K95juTqs5nM1",
        "colab_type": "code",
        "outputId": "4b0d8d4c-0159-4874-9f62-da2130682082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Remove 1 and 2 word responses from dev set.\n",
        "# Split response string by spaces.\n",
        "dev_df['split_response'] = dev_df['response_text'].str.split()\n",
        "# Remove the split responses that have length 1 or 2.\n",
        "mask2 = (dev_df['split_response'].str.len() > 2) \n",
        "dev_df = dev_df.loc[mask2]\n",
        "len(dev_df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2041945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rr_Uonq5sLV",
        "colab_type": "code",
        "outputId": "6bebac64-d2f3-40eb-fdbe-944b1d734417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(dev_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "390738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1oM4o7wtHFd",
        "colab_type": "code",
        "outputId": "1aea1d2e-9f5e-45b3-cce5-d8a1d93bc89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_responses_per_post = train_df.post_id.value_counts().reset_index()\n",
        "num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > 50]\n",
        "posts_to_sample = too_big_posts.post_id.values\n",
        "# this gets all the rows for posts we DON'T need to sample \n",
        "new_train_df = train_df[~train_df.post_id.isin(posts_to_sample)]\n",
        "# this should be true\n",
        "assert(len(too_big_posts) + new_train_df.post_id.nunique() == train_df.post_id.nunique())\n",
        "too_big_post_rows = train_df[train_df.post_id.isin(posts_to_sample)]\n",
        "sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=50)).reset_index(drop=True)\n",
        "new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "new_train_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3721104, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT4xoHcDJQVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgZWntiySs0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shuffle the data\n",
        "# be sure to do this before you extract X's and y's!!\n",
        "train_df = new_train_df.sample(frac=1)\n",
        "dev_df = dev_df.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZJxHTywg7Rq",
        "colab_type": "code",
        "outputId": "96c56001-1bf6-4493-a651-97e15f35ea33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "train_df.op_gender.value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    2725461\n",
              "W     995643\n",
              "Name: op_gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC70Y5RXJlHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "10b43c6c-67fe-459f-a73f-d7425ae8927f"
      },
      "source": [
        "dev_df.op_gender.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    1731288\n",
              "W     310657\n",
              "Name: op_gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvu7r5nThL1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################\n",
        "# Execute this if want to do oversampling.\n",
        "###########################\n",
        "# from sklearn.utils import resample\n",
        "\n",
        "# male = train_df[train_df.op_gender=='M']\n",
        "# female = train_df[train_df.op_gender=='W']\n",
        "\n",
        "# female_upsampled = resample(female,\n",
        "#                           replace=True, # sample with replacement\n",
        "#                           n_samples=len(male), # match number in majority class\n",
        "#                           random_state=27) # reproducible results\n",
        "# upsampled_train = pd.concat([male,female_upsampled])\n",
        "# print(upsampled_train.op_gender.value_counts())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjb6dx8fSs0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace `train_df` with `upsampled_train` if using oversampling.\n",
        "y_train = train_df.op_gender.values\n",
        "y_dev = dev_df.op_gender.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBCoPKh_Ss0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(1)\n",
        "        else:\n",
        "            final_list.append(0)\n",
        "    return final_list\n",
        "            \n",
        "y_train = turn_to_ints(y_train)\n",
        "y_dev = turn_to_ints(y_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN9GFz6xSs0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.asarray(y_train)\n",
        "y_dev = np.asarray(y_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChYxh6oPSs04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_text_list(init_list):\n",
        "    sentences = []\n",
        "    for sentence in init_list:\n",
        "        if type(sentence) != str:\n",
        "            sentences.append(\"\")\n",
        "        else:\n",
        "            sentences.append(sentence)\n",
        "    return sentences\n",
        "\n",
        "# replace `train_df` with `upsampled_train` if using upsampling.\n",
        "new_sentences_train = get_text_list(train_df.response_text.values) \n",
        "new_sentences_test = get_text_list(dev_df.response_text.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b9SE7SjSs06",
        "colab_type": "code",
        "outputId": "2fb3791c-ea11-4ee6-8a0a-9de8c495689d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "time_start = time.time()\n",
        "\n",
        "# this is the default list of filters + apostrophe\n",
        "# added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "tokenizer = Tokenizer(num_words=200000, filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "#Convert the gmtime struct to a string\n",
        "timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "print(\"Tokenized in {}\".format(timeStr))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized in 05 minutes, 29 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyZMBAiySs0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGl1S3HySs1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if SAVE_TOKENIZED_DATA:\n",
        "  x_train_path = 'X_train_{}.pkl'.format(DATASET_NAME)\n",
        "  x_dev_path = 'X_dev_{}.pkl'.format(DATASET_NAME)\n",
        "  y_train_path = 'y_train_{}.pkl'.format(DATASET_NAME)\n",
        "  y_dev_path = 'y_dev_{}.pkl'.format(DATASET_NAME)\n",
        "\n",
        "  with open(x_train_path, 'wb') as file:\n",
        "      pickle.dump(X_train, file)   \n",
        "  with open(x_dev_path, 'wb') as file:\n",
        "      pickle.dump(X_test, file)\n",
        "  with open(y_train_path, 'wb') as file:\n",
        "      pickle.dump(y_train, file)\n",
        "  with open(y_dev_path, 'wb') as file:\n",
        "      pickle.dump(y_dev, file)\n",
        "\n",
        "  # copy to bucket\n",
        "  !gsutil cp /content/{x_train_path} gs://fb-congressional-data/test\n",
        "  !gsutil cp /content/{x_dev_path} gs://fb-congressional-data/\n",
        "  !gsutil cp /content/{y_train_path} gs://fb-congressional-data/\n",
        "  !gsutil cp /content/{y_dev_path} gs://fb-congressional-data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5AeCFGIuKIR",
        "colab_type": "code",
        "outputId": "d9442d5e-27cd-4dc0-c982-6e750aef1a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "- [4 files][  2.1 GiB/  2.1 GiB]   33.3 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "|\n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae5EQ7vbSs1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(embedding_dim),\n",
        "                      tokenizer.word_index, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUTvp7yfut-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trying to figure out which words are empty here\n",
        "# counter = 0\n",
        "# empty_indexes = []\n",
        "# for index, row in enumerate(embedding_matrix):\n",
        "#   if sum(row) == 0:\n",
        "#     empty_indexes.append(index)\n",
        "#     counter += 1\n",
        "#   if counter > 1000:\n",
        "#     break\n",
        "\n",
        "# for idx in empty_indexes:\n",
        "#   try:\n",
        "#     print(tokenizer.index_word[idx])\n",
        "#   except:\n",
        "#     print(\"No entry for {}\".format(idx))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI5vn5zBSs1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hmmmm....\n",
        "# nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
        "# nonzero_elements / vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJtNke4FSs1X",
        "colab_type": "code",
        "outputId": "8e0f8e98-ebdc-45e9-8f4e-176370ac7073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(546265, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb_yr2R9Ss1d",
        "colab_type": "code",
        "outputId": "41a4cb3a-e245-478b-d31f-b4463c3bcafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
        "                           weights=[embedding_matrix], \n",
        "                           input_length=MAX_SEQUENCE_LENGTH, \n",
        "                           trainable=False))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 100)           54626500  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 16, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 54,691,929\n",
            "Trainable params: 65,429\n",
            "Non-trainable params: 54,626,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_9KWVWHAAE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smaller_X_train = X_train[:TRAINING_SET_SIZE]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6gn7HvuAGgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smaller_y_train = y_train[:TRAINING_SET_SIZE]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf5R6UpGDW_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smaller_X_dev = X_test[:VAL_SET_SIZE]\n",
        "smaller_y_dev = y_dev[:VAL_SET_SIZE]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4dbwlaxSs1l",
        "colab_type": "code",
        "outputId": "a502583e-4022-4ee2-a742-8846b3563c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  time_start = time.time()\n",
        "\n",
        "  history = model.fit(X_train, y_train,\n",
        "                      epochs=NUM_EPOCHS,\n",
        "                      verbose=True,\n",
        "                      validation_data=(smaller_X_dev, smaller_y_dev),\n",
        "                      batch_size=BATCH_SIZE)\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "except:\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Trained in {}\".format(timeStr))  "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3721104 samples, validate on 2000000 samples\n",
            "Epoch 1/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.5152 - acc: 0.7662 - val_loss: 0.4517 - val_acc: 0.8394\n",
            "Epoch 2/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4982 - acc: 0.7741 - val_loss: 0.4308 - val_acc: 0.8445\n",
            "Epoch 3/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4930 - acc: 0.7765 - val_loss: 0.4345 - val_acc: 0.8437\n",
            "Epoch 4/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4897 - acc: 0.7780 - val_loss: 0.4480 - val_acc: 0.8378\n",
            "Epoch 5/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4872 - acc: 0.7791 - val_loss: 0.4534 - val_acc: 0.8333\n",
            "Epoch 6/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4853 - acc: 0.7798 - val_loss: 0.4454 - val_acc: 0.8422\n",
            "Epoch 7/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4837 - acc: 0.7804 - val_loss: 0.4483 - val_acc: 0.8345\n",
            "Epoch 8/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4824 - acc: 0.7810 - val_loss: 0.4593 - val_acc: 0.8328\n",
            "Epoch 9/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4814 - acc: 0.7814 - val_loss: 0.4495 - val_acc: 0.8326\n",
            "Epoch 10/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4803 - acc: 0.7818 - val_loss: 0.4540 - val_acc: 0.8349\n",
            "Epoch 11/30\n",
            "3721104/3721104 [==============================] - 102s 28us/sample - loss: 0.4795 - acc: 0.7822 - val_loss: 0.4427 - val_acc: 0.8359\n",
            "Epoch 12/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4787 - acc: 0.7825 - val_loss: 0.4417 - val_acc: 0.8380\n",
            "Epoch 13/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4780 - acc: 0.7828 - val_loss: 0.4368 - val_acc: 0.8407\n",
            "Epoch 14/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4774 - acc: 0.7831 - val_loss: 0.4439 - val_acc: 0.8375\n",
            "Epoch 15/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4769 - acc: 0.7833 - val_loss: 0.4414 - val_acc: 0.8394\n",
            "Epoch 16/30\n",
            "3721104/3721104 [==============================] - 106s 28us/sample - loss: 0.4763 - acc: 0.7834 - val_loss: 0.4465 - val_acc: 0.8394\n",
            "Epoch 17/30\n",
            "3721104/3721104 [==============================] - 102s 27us/sample - loss: 0.4759 - acc: 0.7837 - val_loss: 0.4418 - val_acc: 0.8374\n",
            "Epoch 18/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4754 - acc: 0.7839 - val_loss: 0.4459 - val_acc: 0.8375\n",
            "Epoch 19/30\n",
            "3721104/3721104 [==============================] - 106s 28us/sample - loss: 0.4751 - acc: 0.7841 - val_loss: 0.4529 - val_acc: 0.8291\n",
            "Epoch 20/30\n",
            "3721104/3721104 [==============================] - 106s 28us/sample - loss: 0.4746 - acc: 0.7843 - val_loss: 0.4606 - val_acc: 0.8295\n",
            "Epoch 21/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4742 - acc: 0.7844 - val_loss: 0.4440 - val_acc: 0.8359\n",
            "Epoch 22/30\n",
            "3721104/3721104 [==============================] - 106s 29us/sample - loss: 0.4739 - acc: 0.7846 - val_loss: 0.4481 - val_acc: 0.8349\n",
            "Epoch 23/30\n",
            "3721104/3721104 [==============================] - 103s 28us/sample - loss: 0.4736 - acc: 0.7847 - val_loss: 0.4530 - val_acc: 0.8323\n",
            "Epoch 24/30\n",
            "3721104/3721104 [==============================] - 106s 29us/sample - loss: 0.4733 - acc: 0.7848 - val_loss: 0.4451 - val_acc: 0.8379\n",
            "Epoch 25/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4731 - acc: 0.7849 - val_loss: 0.4586 - val_acc: 0.8297\n",
            "Epoch 26/30\n",
            "3721104/3721104 [==============================] - 105s 28us/sample - loss: 0.4727 - acc: 0.7852 - val_loss: 0.4519 - val_acc: 0.8338\n",
            "Epoch 27/30\n",
            "3721104/3721104 [==============================] - 104s 28us/sample - loss: 0.4725 - acc: 0.7851 - val_loss: 0.4413 - val_acc: 0.8381\n",
            "Epoch 28/30\n",
            "3721104/3721104 [==============================] - 106s 28us/sample - loss: 0.4722 - acc: 0.7853 - val_loss: 0.4542 - val_acc: 0.8336\n",
            "Epoch 29/30\n",
            "3721104/3721104 [==============================] - 103s 28us/sample - loss: 0.4720 - acc: 0.7855 - val_loss: 0.4443 - val_acc: 0.8368\n",
            "Epoch 30/30\n",
            "3721104/3721104 [==============================] - 106s 29us/sample - loss: 0.4718 - acc: 0.7855 - val_loss: 0.4525 - val_acc: 0.8329\n",
            "Trained in 52 minutes, 17 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4P5Y5wgSs1o",
        "colab_type": "code",
        "outputId": "a4c39e49-c6e4-4e6f-ee04-2210f9800d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_dev, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.7870\n",
            "Testing Accuracy:  0.8329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZanpp-O9oiz",
        "colab_type": "code",
        "outputId": "f6b741b2-2d3d-455f-b58d-89dc0307b668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# ROC AUC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(X_test, verbose=0)\n",
        "# reduce to 1d array\n",
        "yhat_probs = yhat_probs[:,0]\n",
        "auc = roc_auc_score(y_dev, yhat_probs)\n",
        "print('ROC AUC:', auc)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.6252946314091796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5G9XjaGJh-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "e6b175b7-92e2-4fb1-8527-e4c8eab360fe"
      },
      "source": [
        "# can't get this to work\n",
        "plot_model(history)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2ae95f153bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Create graph nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute '_layers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccL7n659KbQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = yhat_probs # model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhpB8QsgGMZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_df['probs'] = preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T2IxdCMGf2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'M'\n",
        "  else:\n",
        "    return 'W'\n",
        "\n",
        "dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzbasnNWGg5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_preds = dev_df[dev_df.op_gender!=dev_df.preds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAYve8ZhG7wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_preds.op_gender.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJJrm2LxHFzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# total proportion of preds for women\n",
        "dev_df.preds.value_counts()['W'] / len(dev_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxFooJUbHVUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#random sample of mistakes\n",
        "wrong_preds.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaswseIjHc8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# most confident wrong predictions where the answer was F but they thought M\n",
        "# same as before - references to a male politician \n",
        "wrong_preds.sort_values('probs', ascending=False)[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoJzrEOfIct2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# most confident wrong predictions where the answer was F but they thought M\n",
        "# same as before - references to a male politician \n",
        "wrong_preds.sort_values('probs', ascending=True)[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}