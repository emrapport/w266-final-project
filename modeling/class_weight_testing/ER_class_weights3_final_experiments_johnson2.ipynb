{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_experiments_johnson2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/ER_class_weights3_final_experiments_johnson2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHeoGlIX2sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"Mon_11_25_johnson2_W_weight_double\"\n",
        "\n",
        "hyp_combos = [{'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 20,\n",
        "                'BATCH_SIZE': 10000,\n",
        "                'MAX_SEQUENCE_LENGTH': 40,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 3,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyp1cqW7BHY",
        "colab_type": "code",
        "outputId": "062464dc-4d3d-4acf-8f3f-b5ce81c10a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# examples of all the hyp dicts for each arch\n",
        "{'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "{'ARCHITECTURE': 'JOHNSON',\n",
        "                 'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 15,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "{'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 64,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'KIM',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZE': 64,\n",
              "  'DROPOUT_RATE': 0.2,\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [2, 4, 6],\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 10,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "outputId": "9170f14d-69aa-4870-93fd-298cbdb0cd62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "outputId": "545124e7-af07-4aad-f284-bdfc47cc2a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, roc_curve, roc_auc_score, precision_recall_curve, auc\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/18/77b11d91ddd0659d2588ff52780e56cb3678fb1a83eeb47cfe14f9c6ebb5/gcsfs-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.5.0\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "outputId": "53c857c8-12a4-42be-e7fa-e8896ce9c2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "/ [4 files][  2.1 GiB/  2.1 GiB]  116.3 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "- [5 files][  2.9 GiB/  2.9 GiB]  159.7 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    female = sum(final_list)\n",
        "    male = len(final_list)-sum(final_list)\n",
        "    percent_M = male/len(final_list)\n",
        "    print('M: {}, W: {}, percent M: {}'.format(male,female,percent_M))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    democrat = sum(final_list)\n",
        "    republican = len(final_list)-sum(final_list)\n",
        "    percent_repub = republican/len(final_list)\n",
        "    print('R: {}, D: {}, percent R: {}'.format(republican,democrat,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        class_weight = {0: 1,\n",
        "                                        1: 3},\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'W'\n",
        "  else:\n",
        "    return 'M'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Democrat'\n",
        "  else:\n",
        "    return 'Congress_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes,\n",
        "                   dropout_rate):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(dropout_rate)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'],\n",
        "                           hyp_dict['DROPOUT_RATE'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "outputId": "5cc881c9-6ddf-4c97-d5e5-c13e57ebbf14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_gender,preds)\n",
        "  print(\"gender ROC_AUC:\",roc_auc_score(y_dev_gender,preds))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"gender precision:\",precision_score(y_dev_gender,preds.round()))\n",
        "  print(\"gender recall:\",recall_score(y_dev_gender,preds.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_gender,preds)\n",
        "  print(\"gender precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Democrat' in dev_df.preds2.value_counts():\n",
        "    proportion_dem_predicted = dev_df.preds2.value_counts()['Congress_Democrat'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_dem_predicted = 0\n",
        "  print(\"Proportion of predictions for Democrat class: {}\".format(proportion_dem_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_party,preds2)\n",
        "  print(\"party ROC_AUC:\",roc_auc_score(y_dev_party,preds2))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"party precision:\",precision_score(y_dev_party,preds2.round()))\n",
        "  print(\"party recall:\",recall_score(y_dev_party,preds2.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_party,preds2)\n",
        "  print(\"party precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755947 training rows\n",
            "Responses include only the first 20 and last 20 words\n",
            "Getting labels\n",
            "training set:\n",
            "M: 2752041, W: 1003906, percent M: 0.7327156107367863\n",
            "dev set:\n",
            "M: 1821965, W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "R: 2337054, D: 1402563, percent R: 0.6249447470155366\n",
            "dev set:\n",
            "R: 1593280, D: 557512, percent R: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 24 seconds\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 40, 50)            250150    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 40, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 40, 128)           19328     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 40, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 516,007\n",
            "Trainable params: 265,857\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3755947 samples, validate on 2150792 samples\n",
            "Epoch 1/20\n",
            "3755947/3755947 [==============================] - 76s 20us/step - loss: 0.9436 - acc: 0.6040 - val_loss: 0.6584 - val_acc: 0.5676\n",
            "Epoch 2/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8906 - acc: 0.6381 - val_loss: 0.6196 - val_acc: 0.6654\n",
            "Epoch 3/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8793 - acc: 0.6422 - val_loss: 0.6149 - val_acc: 0.6623\n",
            "Epoch 4/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8725 - acc: 0.6463 - val_loss: 0.6112 - val_acc: 0.6830\n",
            "Epoch 5/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8676 - acc: 0.6495 - val_loss: 0.6529 - val_acc: 0.6047\n",
            "Epoch 6/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8642 - acc: 0.6513 - val_loss: 0.6456 - val_acc: 0.6232\n",
            "Epoch 7/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8614 - acc: 0.6520 - val_loss: 0.6675 - val_acc: 0.5858\n",
            "Epoch 8/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8587 - acc: 0.6534 - val_loss: 0.6501 - val_acc: 0.5935\n",
            "Epoch 9/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8565 - acc: 0.6546 - val_loss: 0.6180 - val_acc: 0.6371\n",
            "Epoch 10/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8552 - acc: 0.6547 - val_loss: 0.6224 - val_acc: 0.6614\n",
            "Epoch 11/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8535 - acc: 0.6561 - val_loss: 0.6237 - val_acc: 0.6417\n",
            "Epoch 12/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8523 - acc: 0.6562 - val_loss: 0.6233 - val_acc: 0.6481\n",
            "Epoch 13/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8511 - acc: 0.6567 - val_loss: 0.6557 - val_acc: 0.6104\n",
            "Epoch 14/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8497 - acc: 0.6572 - val_loss: 0.6434 - val_acc: 0.6208\n",
            "Epoch 15/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8488 - acc: 0.6569 - val_loss: 0.6410 - val_acc: 0.6145\n",
            "Epoch 16/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8474 - acc: 0.6573 - val_loss: 0.6590 - val_acc: 0.5965\n",
            "Epoch 17/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8466 - acc: 0.6579 - val_loss: 0.6658 - val_acc: 0.5799\n",
            "Epoch 18/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8457 - acc: 0.6580 - val_loss: 0.6477 - val_acc: 0.6009\n",
            "Epoch 19/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8449 - acc: 0.6586 - val_loss: 0.6365 - val_acc: 0.6271\n",
            "Epoch 20/20\n",
            "3755947/3755947 [==============================] - 71s 19us/step - loss: 0.8442 - acc: 0.6584 - val_loss: 0.6454 - val_acc: 0.6229\n",
            "Trained in 23 minutes, 45 seconds\n",
            "Copying file:///content/Mon_11_25_johnson2_W_weight_double_model_0_gender_1575139598.4708147.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/4.1 MiB.                                      \n",
            "Proportion of predictions for W class: 0.4133240220346737\n",
            "gender ROC_AUC: 0.6790690251046619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkpwSgYhIkvt/UIxhJbt/oFgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "gender precision: 0.22882783973434542\n",
            "gender recall: 0.6186292488147263\n",
            "gender precision-recall AUC: 0.3074119786866848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMyvkJGFmZoX+E+PPd2HuCM25AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739617 samples, validate on 2150792 samples\n",
            "Epoch 1/20\n",
            "3739617/3739617 [==============================] - 72s 19us/step - loss: 1.0457 - acc: 0.4736 - val_loss: 0.9152 - val_acc: 0.3689\n",
            "Epoch 2/20\n",
            "3739617/3739617 [==============================] - 71s 19us/step - loss: 0.9774 - acc: 0.5371 - val_loss: 0.9118 - val_acc: 0.3737\n",
            "Epoch 3/20\n",
            "3040000/3739617 [=======================>......] - ETA: 11s - loss: 0.9571 - acc: 0.5542"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4743f8f90163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0mparty_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}_model_{}_party_{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PREFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparty_model_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Note: changed this to model2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0mpreds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     with temporary_clearer(), _display_stdin_widget(\n\u001b[0;32m--> 181\u001b[0;31m         delay_millis=500) as update_stdin_widget:\n\u001b[0m\u001b[1;32m    182\u001b[0m       \u001b[0;31m# TODO(b/115531839): Ensure that subprocesses are terminated upon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# interrupt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0mshell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mdisplay_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_display_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delayMillis'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelay_millis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdisplay_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mecho_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_echo_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lToXFzF6PbK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "dev_df.probs.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLsmpnYQPcn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}