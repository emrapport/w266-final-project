{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_experiments_johnson2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrapport/w266-final-project/blob/master/ER_class_weights_final_experiments_johnson2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVfEbx0cZNNp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHeoGlIX2sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name of subfolder under models/ where trained models should go\n",
        "MODEL_PREFIX = \"Mon_11_25_johnson2_W_weight_double\"\n",
        "\n",
        "hyp_combos = [{'ARCHITECTURE': 'JOHNSON',\n",
        "                'NUM_EPOCHS': 20,\n",
        "                'BATCH_SIZE': 10000,\n",
        "                'MAX_SEQUENCE_LENGTH': 40,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 3,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}               \n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyp1cqW7BHY",
        "colab_type": "code",
        "outputId": "948acd9d-fdf5-493f-e606-bb79758b0ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# examples of all the hyp dicts for each arch\n",
        "{'ARCHITECTURE': 'BYO',\n",
        "                    'NUM_EPOCHS': 1,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                'NUM_LAYERS': 2,\n",
        "                'CONV_LAYER_SIZES': [128, 128],\n",
        "                'FILTER_SIZES': [4, 4],\n",
        "                'DROPOUT_RATES': [.2, .2],\n",
        "                'FINAL_DENSE_LAYER_SIZE': 10,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},\n",
        "{'ARCHITECTURE': 'JOHNSON',\n",
        "                 'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                # a block is a set of two conv layers and a max pooling layer\n",
        "                # max pooling layers currently always have size 3 stride 2 like in paper\n",
        "                # we could paramaterize that if we want \n",
        "                'NUM_BLOCKS': 15,\n",
        "                'CONV_LAYER_SIZE': 128,\n",
        "                'FILTER_SIZE': 3,\n",
        "                'DROPOUT_RATE': .5,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True}, \n",
        "{'ARCHITECTURE': 'KIM',\n",
        "                'NUM_EPOCHS': 10,\n",
        "                'BATCH_SIZE': 1000,\n",
        "                'MAX_SEQUENCE_LENGTH': 20,\n",
        "                'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
        "                'MAX_RESPONSES_PER_POST': 50,\n",
        "                 # the true conv layer size is the \n",
        "                 # conv_layer_size multiplied by length of filter sizes\n",
        "                'CONV_LAYER_SIZE': 64,\n",
        "                'FILTER_SIZES': [2, 4, 6],\n",
        "                'DROPOUT_RATE': .2,\n",
        "                # embed dim needs to map to one of the glove versions: 50, 100, 200, 300 \n",
        "                'EMBEDDING_DIM': 50,\n",
        "                'REMOVE_SHORT_RESP_LENGTH':1,\n",
        "                'SAMPLE_FROM_BEG_AND_END':True},"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ARCHITECTURE': 'KIM',\n",
              "  'BATCH_SIZE': 1000,\n",
              "  'CONV_LAYER_SIZE': 64,\n",
              "  'DROPOUT_RATE': 0.2,\n",
              "  'EMBEDDING_DIM': 50,\n",
              "  'FILTER_SIZES': [2, 4, 6],\n",
              "  'MAX_RESPONSES_PER_POST': 50,\n",
              "  'MAX_SEQUENCE_LENGTH': 20,\n",
              "  'NUM_EPOCHS': 10,\n",
              "  'N_MOST_FREQ_WORDS_TO_KEEP': 5000,\n",
              "  'REMOVE_SHORT_RESP_LENGTH': 1,\n",
              "  'SAMPLE_FROM_BEG_AND_END': True},)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGfRSm8JdMvc",
        "colab_type": "code",
        "outputId": "46e93018-6b74-4ebc-adb8-0c0832d6cd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## check to ensure hyps are in agreement\n",
        "for i,hyp_combo in enumerate(hyp_combos):\n",
        "  assert hyp_combo['ARCHITECTURE'] in ['BYO', 'KIM', 'JOHNSON']\n",
        "  if hyp_combo['ARCHITECTURE'] == 'BYO':\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['CONV_LAYER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['FILTER_SIZES'])\n",
        "    assert hyp_combo['NUM_LAYERS'] == len(hyp_combo['DROPOUT_RATES'])\n",
        "  if hyp_combo['ARCHITECTURE'] == 'KIM':\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZES'])==list\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  if hyp_combo['ARCHITECTURE'] == 'JOHNSON':\n",
        "    assert type(hyp_combo['NUM_BLOCKS'])==int\n",
        "    assert type(hyp_combo['CONV_LAYER_SIZE'])==int\n",
        "    assert type(hyp_combo['FILTER_SIZE'])==int\n",
        "    assert type(hyp_combo['DROPOUT_RATE'])==float\n",
        "  print(\"Model {} passed\".format(i))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 0 passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s79t_aJZsYG",
        "colab_type": "code",
        "outputId": "25837529-4911-4067-a0a7-518fed62916a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "## all this stuff just needs to get run one time per notebook\n",
        "# Set seeds for reproducible results.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, roc_curve, roc_auc_score, precision_recall_curve, auc\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from scipy.sparse import hstack, vstack\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import Sequential, layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "!pip install gcsfs\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "project_id = 'w266-251323'\n",
        "import uuid\n",
        "bucket_name = 'fb-congressional-data/'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {project_id}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/65/e2/05f903ce8f77804127195cfcc1ca8b500a3157a1572dcc4b82bf5af01564/gcsfs-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.7)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.4.0\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugAe-Vx04Pf",
        "colab_type": "code",
        "outputId": "f67968eb-43c3-4c47-f893-46186785c26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "train_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/train.csv\", index_col=0)\n",
        "dev_df = pd.read_csv(\"gs://fb-congressional-data/contraction_expanded_data/dev.csv\", index_col=0)\n",
        "!gsutil cp gs://fb-congressional-data/glove* /tmp/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying gs://fb-congressional-data/glove.6B.100d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.200d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.300d.txt...\n",
            "Copying gs://fb-congressional-data/glove.6B.50d.txt...\n",
            "\\ [4 files][  2.1 GiB/  2.1 GiB]   92.2 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fb-congressional-data/glove.6B.zip...\n",
            "| [5 files][  2.9 GiB/  2.9 GiB]  153.4 MiB/s                                   \n",
            "Operation completed over 5 objects/2.9 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysaWA5e_aGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all the functions go here\n",
        "def remove_excess_rows_per_post(df, max_per_post):\n",
        "  num_responses_per_post = df.post_id.value_counts().reset_index()\n",
        "  num_responses_per_post.columns = ['post_id', 'num_responses']\n",
        "  \n",
        "  too_big_posts = num_responses_per_post[num_responses_per_post.num_responses > max_per_post]\n",
        "  posts_to_sample = too_big_posts.post_id.values\n",
        "  \n",
        "  # this gets all the rows for posts we DON'T need to sample \n",
        "  new_train_df = df[~df.post_id.isin(posts_to_sample)]\n",
        "  # this should be true\n",
        "  assert(len(too_big_posts) + new_train_df.post_id.nunique() == df.post_id.nunique())\n",
        "  \n",
        "  too_big_post_rows = df[df.post_id.isin(posts_to_sample)]\n",
        "  sampled_rows = too_big_post_rows.groupby('post_id').apply(lambda x: x.sample(n=max_per_post)).reset_index(drop=True)\n",
        "  new_train_df = pd.concat([new_train_df, sampled_rows])\n",
        "  \n",
        "  return new_train_df\n",
        "\n",
        "def get_labels(train_df, test_df, party_label_ind):\n",
        "\n",
        "  def turn_to_ints(li):\n",
        "    final_list = []\n",
        "    for gender in li:\n",
        "        if gender=='M':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    female = sum(final_list)\n",
        "    male = len(final_list)-sum(final_list)\n",
        "    percent_M = male/len(final_list)\n",
        "    print('M: {}, W: {}, percent M: {}'.format(male,female,percent_M))\n",
        "    return final_list\n",
        "\n",
        "  def turn_to_ints_party(li):\n",
        "    final_list = []\n",
        "    for party in li:\n",
        "        if party=='Congress_Republican':\n",
        "            final_list.append(0)\n",
        "        else:\n",
        "            final_list.append(1)\n",
        "    democrat = sum(final_list)\n",
        "    republican = len(final_list)-sum(final_list)\n",
        "    percent_repub = republican/len(final_list)\n",
        "    print('R: {}, D: {}, percent R: {}'.format(republican,democrat,percent_repub))\n",
        "    return final_list\n",
        "\n",
        "  if party_label_ind:\n",
        "\n",
        "    y_train = train_df.op_category.values\n",
        "    y_dev = test_df.op_category.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints_party(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints_party(y_dev) \n",
        "\n",
        "  else:\n",
        "    y_train = train_df.op_gender.values\n",
        "    y_dev = test_df.op_gender.values\n",
        "    print('training set:')\n",
        "    y_train = turn_to_ints(y_train)\n",
        "    print('dev set:')\n",
        "    y_dev = turn_to_ints(y_dev)\n",
        "\n",
        "  y_train = np.asarray(y_train)\n",
        "  y_dev = np.asarray(y_dev)\n",
        "\n",
        "  return y_train, y_dev\n",
        "\n",
        "def get_inputs(train_df, \n",
        "               test_df, \n",
        "               party_train_df,\n",
        "               party_dev_df,\n",
        "               n_words_to_keep,\n",
        "               max_seq_length):\n",
        "  def get_text_list(init_list):\n",
        "      sentences = []\n",
        "      for sentence in init_list:\n",
        "          if type(sentence) != str:\n",
        "              sentences.append(\"\")\n",
        "          else:\n",
        "              sentences.append(sentence)\n",
        "      return sentences\n",
        "\n",
        "  new_sentences_train = get_text_list(train_df.response_text.values)\n",
        "  new_sentences_test = get_text_list(dev_df.response_text.values)\n",
        "  party_new_sentences_train = get_text_list(party_train_df.response_text.values)\n",
        "  party_new_sentences_test = get_text_list(party_dev_df.response_text.values)\n",
        "\n",
        "  time_start = time.time()\n",
        "\n",
        "  # this is the default list of filters + apostrophe\n",
        "  # added because we have dealt with common contractions, so other apostrophes should mostly be possessive \n",
        "  tokenizer = Tokenizer(filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='UNK')\n",
        "  tokenizer.fit_on_texts(new_sentences_train)\n",
        "\n",
        "  currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "  #Convert the gmtime struct to a string\n",
        "  timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "  print(\"Tokenized in {}\".format(timeStr))\n",
        "\n",
        "  # suggestion from this issue: https://github.com/keras-team/keras/issues/8092\n",
        "  # seems like OOV and num_words don't work correctly by default \n",
        "  tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() \n",
        "                              if i <= n_words_to_keep + 1} \n",
        "  tokenizer.word_index[tokenizer.oov_token] = n_words_to_keep + 1\n",
        "\n",
        "  X_train = tokenizer.texts_to_sequences(new_sentences_train)\n",
        "  X_test = tokenizer.texts_to_sequences(new_sentences_test)\n",
        "  X_train = pad_sequences(X_train, padding='post', maxlen=max_seq_length)\n",
        "  X_test = pad_sequences(X_test, padding='post', maxlen=max_seq_length)\n",
        "\n",
        "  X_train_party = tokenizer.texts_to_sequences(party_new_sentences_train)\n",
        "  X_test_party = tokenizer.texts_to_sequences(party_new_sentences_test)\n",
        "  X_train_party = pad_sequences(X_train_party, padding='post', maxlen=max_seq_length)\n",
        "  X_test_party = pad_sequences(X_test_party, padding='post', maxlen=max_seq_length)\n",
        "  return X_train, X_test, X_train_party, X_test_party, tokenizer\n",
        "\n",
        "def create_embedding_matrix(filepath, \n",
        "                            word_index, \n",
        "                            embedding_dim):\n",
        "    vocab_size = len(word_index) + 2  # Now we have to add 2 (reserved 0 plus the manual UNK token)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def train_model(model, \n",
        "                train_inputs,\n",
        "                dev_inputs,\n",
        "                train_labels,\n",
        "                dev_labels,\n",
        "                num_epochs,\n",
        "                batch_size):\n",
        "  try:\n",
        "    time_start = time.time()\n",
        "\n",
        "    history = model.fit(train_inputs, train_labels,\n",
        "                        epochs=num_epochs,\n",
        "                        verbose=True,\n",
        "                        class_weight = {0: 1,\n",
        "                                        1: 2},\n",
        "                        validation_data=(dev_inputs, dev_labels),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))\n",
        "\n",
        "  except Exception as ex:\n",
        "    print(\"Exception: {}\".format(ex))\n",
        "    currentTime = time.gmtime(time.time() - time_start)\n",
        "\n",
        "    #Convert the gmtime struct to a string\n",
        "    timeStr = time.strftime(\"%M minutes, %S seconds\", currentTime)\n",
        "\n",
        "    print(\"Trained in {}\".format(timeStr))  \n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def pred_to_label(row):\n",
        "  if row['probs'] >= .5:\n",
        "    return 'W'\n",
        "  else:\n",
        "    return 'M'\n",
        "\n",
        "def pred_to_party_label(row):\n",
        "  if row['probs2'] >= .5:\n",
        "    return 'Congress_Democrat'\n",
        "  else:\n",
        "    return 'Congress_Republican'\n",
        "\n",
        "def remove_short_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column and removes \n",
        "  responses shorter than or equal to n. Returns new dataframe.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  mask = (responses_df['split_response'].str.len() > n)\n",
        "  responses_df = responses_df.loc[mask]\n",
        "  responses_df = responses_df.drop(columns='split_response', axis = 1)\n",
        "  return responses_df\n",
        "\n",
        "def shorten_single_response(series_list,length):\n",
        "  '''Take a list of strings and a goal max length. Return the goal length list\n",
        "  taken half from the beginning of the orginal list and half from the end of \n",
        "  the original list.'''\n",
        "  if type(series_list) != float:\n",
        "    if len(series_list) > length:\n",
        "      new_list = series_list[:(length//2+length % 2)] + series_list[-length//2:]\n",
        "      return new_list\n",
        "    else: \n",
        "      return series_list\n",
        "  else:\n",
        "    return series_list\n",
        "\n",
        "def get_beg_end_responses(responses_df,n):\n",
        "  '''Takes a dataframe that includes a response_text column, creates new\n",
        "  response_text strings of word length n using the first n/2 words and last n/2\n",
        "  words of the response_text and returns a new dataframe with the new response_text.'''\n",
        "  responses_df['split_response'] = responses_df['response_text'].str.split()\n",
        "  responses_df['short_response'] = responses_df['split_response'].apply(shorten_single_response,args=(n,))\n",
        "  responses_df['response_text'] = responses_df['short_response'].str.join(' ')\n",
        "  responses_df = responses_df.drop(columns=['split_response','short_response'], axis=1)\n",
        "  return responses_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IJ8-QISYjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generic_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_layers,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate,\n",
        "                       final_hidden_dense_size):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    for i in range(num_layers):\n",
        "      model.add(layers.Conv1D(conv_layer_size[i], filter_size[i], activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Dropout(dropout_rate[i]))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(final_hidden_dense_size, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_kim_model(embedding_matrix, \n",
        "                   max_seq_length,\n",
        "                   conv_layer_size,\n",
        "                   filter_sizes,\n",
        "                   dropout_rate):\n",
        "  # initialize model so that finally won't throw error\n",
        "  model = None\n",
        "\n",
        "  try:\n",
        "    convs = []\n",
        "\n",
        "    sequence_input = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "    embedded_sequences = layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False)(sequence_input)\n",
        "\n",
        "    for fsz in filter_sizes:\n",
        "      l_conv = layers.Conv1D(conv_layer_size, fsz,activation='relu')(embedded_sequences)\n",
        "      convs.append(l_conv)\n",
        "\n",
        "    l_merge = layers.Concatenate(axis=1)(convs)\n",
        "    l_gmp = layers.GlobalMaxPooling1D()(l_merge)\n",
        "\n",
        "    preds = layers.Dense(1, activation='sigmoid')(l_gmp)\n",
        "    do_preds = layers.Dropout(dropout_rate)(preds)\n",
        "\n",
        "    model = Model(sequence_input, do_preds)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_johnson_model(embedding_matrix, \n",
        "                       max_seq_length,\n",
        "                       num_blocks,\n",
        "                       conv_layer_size,\n",
        "                       filter_size,\n",
        "                       dropout_rate):\n",
        "  model = Sequential()\n",
        "\n",
        "  try:\n",
        "    model.add(layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], \n",
        "                              weights=[embedding_matrix], \n",
        "                              input_length=max_seq_length, \n",
        "                              trainable=False))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      model.add(layers.Conv1D(conv_layer_size, filter_size, activation='relu', padding=\"same\"))\n",
        "      # we could paramatarize this max pooling eventually if we have time. \n",
        "      # values below come from paper \n",
        "      model.add(layers.MaxPooling1D(pool_size=3, strides=2))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  except Exception as ex:\n",
        "    print(ex)\n",
        "  finally:\n",
        "    return model\n",
        "\n",
        "def make_model(embedding_matrix, hyp_dict):\n",
        "  if hyp_dict['ARCHITECTURE']=='KIM':\n",
        "    model = make_kim_model(embedding_matrix,\n",
        "                           hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                           hyp_dict['CONV_LAYER_SIZE'],\n",
        "                           hyp_dict['FILTER_SIZES'],\n",
        "                           hyp_dict['DROPOUT_RATE'])\n",
        "  \n",
        "  elif hyp_dict['ARCHITECTURE']=='JOHNSON':\n",
        "    model = make_johnson_model(embedding_matrix,\n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_BLOCKS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZE'],\n",
        "                               hyp_dict['FILTER_SIZE'],\n",
        "                               hyp_dict['DROPOUT_RATE'])\n",
        "  elif hyp_dict['ARCHITECTURE']=='BYO':\n",
        "    model = make_generic_model(embedding_matrix, \n",
        "                               hyp_dict['MAX_SEQUENCE_LENGTH'],\n",
        "                               hyp_dict['NUM_LAYERS'],\n",
        "                               hyp_dict['CONV_LAYER_SIZES'],\n",
        "                               hyp_dict['FILTER_SIZES'],\n",
        "                               hyp_dict['DROPOUT_RATES'],\n",
        "                               hyp_dict['FINAL_DENSE_LAYER_SIZE'])\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s844qbPgZi2s",
        "colab_type": "code",
        "outputId": "de230921-cc7f-4406-cfe8-47b1ee913f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# timestamp is shared across all runs\n",
        "timestamp = time.time()\n",
        "\n",
        "for i, hyp_dict in enumerate(hyp_combos):\n",
        "  print(\"Training Model {}\".format(i))\n",
        "  new_train_df = remove_excess_rows_per_post(train_df, hyp_dict['MAX_RESPONSES_PER_POST'])\n",
        "  print(\"Limiting to {} responses per post resulted in {} training rows\".format(hyp_dict['MAX_RESPONSES_PER_POST'],new_train_df.shape[0]))\n",
        "  if hyp_dict['REMOVE_SHORT_RESP_LENGTH'] > 0:\n",
        "    new_train_df = remove_short_responses(new_train_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    dev_df =remove_short_responses(dev_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    print(\"Removing responses under {} words resulted in {} training rows\".format((hyp_dict['REMOVE_SHORT_RESP_LENGTH']+1),new_train_df.shape[0]))\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = remove_short_responses(test_df,hyp_dict['REMOVE_SHORT_RESP_LENGTH'])\n",
        "    ###########################################\n",
        "  if hyp_dict['SAMPLE_FROM_BEG_AND_END']:\n",
        "    length = hyp_dict['MAX_SEQUENCE_LENGTH']\n",
        "    new_train_df = get_beg_end_responses(new_train_df,length)\n",
        "    dev_df = get_beg_end_responses(dev_df,length)\n",
        "    ######### Add if using test data###########\n",
        "    # test_df = get_beg_end_responses(test_df,length)\n",
        "    ###########################################\n",
        "    print(\"Responses include only the first {} and last {} words\".format((length//2+length%2),length//2))\n",
        "  else:\n",
        "    print(\"Responses include only the first {} words\".format(hyp_dict['MAX_SEQUENCE_LENGTH']))\n",
        "\n",
        "  new_train_df = new_train_df.sample(frac=1)\n",
        "  dev_df = dev_df.sample(frac=1)\n",
        "\n",
        "\n",
        "  party_train_df = new_train_df[new_train_df.op_category!='Congress_Independent']\n",
        "  party_dev_df = dev_df[dev_df.op_category!='Congress_Independent']\n",
        "\n",
        "  # get two sets of labels: gender and party\n",
        "  print(\"Getting labels\")\n",
        "  y_train_gender, y_dev_gender = get_labels(new_train_df, dev_df, False)\n",
        "  y_train_party, y_dev_party = get_labels(party_train_df, party_dev_df, True)\n",
        "\n",
        "  print(\"Getting inputs\")\n",
        "  X_train, X_test, X_train_party, X_test_party, tokenizer = get_inputs(new_train_df, \n",
        "                                                                       dev_df, \n",
        "                                                                       party_train_df,\n",
        "                                                                       party_dev_df,\n",
        "                                                                       hyp_dict['N_MOST_FREQ_WORDS_TO_KEEP'], \n",
        "                                                                       hyp_dict['MAX_SEQUENCE_LENGTH'])\n",
        "  embedding_matrix = create_embedding_matrix(\n",
        "                     '/tmp/glove.6B.{}d.txt'.format(hyp_dict['EMBEDDING_DIM']),\n",
        "                      tokenizer.word_index, hyp_dict['EMBEDDING_DIM'])\n",
        "  \n",
        "  # gender model\n",
        "  model = make_model(embedding_matrix, \n",
        "                     hyp_dict)\n",
        "  print(model.summary())\n",
        "  trained_model = train_model(model,\n",
        "                              X_train,\n",
        "                              X_test,\n",
        "                              y_train_gender,\n",
        "                              y_dev_gender,\n",
        "                              hyp_dict['NUM_EPOCHS'],\n",
        "                              hyp_dict['BATCH_SIZE']\n",
        "                              )\n",
        "  \n",
        "  # adding epoch time just in case we accidentally re-use the same prefixes \n",
        "  gender_model_path = '{}_model_{}_gender_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model.save(gender_model_path)\n",
        "  !gsutil cp /content/{gender_model_path} gs://fb-congressional-data/models/{gender_model_path}\n",
        "\n",
        "  preds = model.predict(X_test)\n",
        "  dev_df['probs'] = preds\n",
        "  dev_df['preds'] = dev_df.apply(pred_to_label, axis=1)\n",
        "\n",
        "  if 'W' in dev_df.preds.value_counts():\n",
        "    proportion_women_predicted = dev_df.preds.value_counts()['W'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_women_predicted = 0\n",
        "  print(\"Proportion of predictions for W class: {}\".format(proportion_women_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_gender,preds)\n",
        "  print(\"gender ROC_AUC:\",roc_auc_score(y_dev_gender,preds))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"gender precision:\",precision_score(y_dev_gender,preds.round()))\n",
        "  print(\"gender recall:\",recall_score(y_dev_gender,preds.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_gender,preds)\n",
        "  print(\"gender precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Gender Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Gender Prediction, Model {}'.format(i))\n",
        "  dev_df.probs.hist(bins=20)\n",
        "  plt.show()\n",
        "\n",
        "  # party model\n",
        "  model2 = make_model(embedding_matrix, \n",
        "                      hyp_dict)\n",
        "  trained_model2 = train_model(model2,\n",
        "                               X_train_party,\n",
        "                               X_test_party,\n",
        "                               y_train_party,\n",
        "                               y_dev_party,\n",
        "                               hyp_dict['NUM_EPOCHS'],\n",
        "                               hyp_dict['BATCH_SIZE'])\n",
        "  \n",
        "  party_model_path = '{}_model_{}_party_{}.h5'.format(MODEL_PREFIX, i, timestamp)\n",
        "  model2.save(party_model_path) # Note: changed this to model2\n",
        "  !gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}\n",
        "\n",
        "  preds2 = model2.predict(X_test)\n",
        "  dev_df['probs2'] = preds2\n",
        "  dev_df['preds2'] = dev_df.apply(pred_to_party_label, axis=1)\n",
        "\n",
        "  if 'Congress_Democrat' in dev_df.preds2.value_counts():\n",
        "    proportion_dem_predicted = dev_df.preds2.value_counts()['Congress_Democrat'] / len(dev_df)\n",
        "  else:\n",
        "    proportion_dem_predicted = 0\n",
        "  print(\"Proportion of predictions for Democrat class: {}\".format(proportion_dem_predicted))\n",
        "\n",
        "  #ROC-AUC\n",
        "  fpr,tpr,thresholds = roc_curve(y_dev_party,preds2)\n",
        "  print(\"party ROC_AUC:\",roc_auc_score(y_dev_party,preds2))\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # precision-recall\n",
        "  print(\"party precision:\",precision_score(y_dev_party,preds2.round()))\n",
        "  print(\"party recall:\",recall_score(y_dev_party,preds2.round()))\n",
        "  precision, recall, thresholds = precision_recall_curve(y_dev_party,preds2)\n",
        "  print(\"party precision-recall AUC:\",auc(recall,precision))\n",
        "  plt.plot(recall,precision)\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Precision-Recall for Party Prediction, Model {}'.format(i))\n",
        "  plt.show()\n",
        "\n",
        "  # Plot probabilities.\n",
        "  plt.figure()\n",
        "  plt.title('Probablities for Party Prediction, Model {}'.format(i))\n",
        "  dev_df.probs2.hist(bins=20)\n",
        "  plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n",
            "Limiting to 50 responses per post resulted in 3962284 training rows\n",
            "Removing responses under 2 words resulted in 3755947 training rows\n",
            "Responses include only the first 20 and last 20 words\n",
            "Getting labels\n",
            "training set:\n",
            "M: 2752041, W: 1003906, percent M: 0.7327156107367863\n",
            "dev set:\n",
            "M: 1821965, W: 328827, percent M: 0.8471135284118595\n",
            "training set:\n",
            "R: 2337054, D: 1402563, percent R: 0.6249447470155366\n",
            "dev set:\n",
            "R: 1593280, D: 557512, percent R: 0.7407875796450796\n",
            "Getting inputs\n",
            "Tokenized in 01 minutes, 44 seconds\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 40, 50)            250150    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 40, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 40, 128)           19328     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 40, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 19, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 9, 128)            49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 516,007\n",
            "Trainable params: 265,857\n",
            "Non-trainable params: 250,150\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3755947 samples, validate on 2150792 samples\n",
            "Epoch 1/20\n",
            "3755947/3755947 [==============================] - 77s 21us/step - loss: 0.7740 - acc: 0.7476 - val_loss: 0.5430 - val_acc: 0.8040\n",
            "Epoch 2/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.7231 - acc: 0.7628 - val_loss: 0.5151 - val_acc: 0.8168\n",
            "Epoch 3/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.7133 - acc: 0.7640 - val_loss: 0.5217 - val_acc: 0.8024\n",
            "Epoch 4/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.7080 - acc: 0.7651 - val_loss: 0.5095 - val_acc: 0.8150\n",
            "Epoch 5/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.7041 - acc: 0.7658 - val_loss: 0.5700 - val_acc: 0.7460\n",
            "Epoch 6/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.7012 - acc: 0.7661 - val_loss: 0.5450 - val_acc: 0.7769\n",
            "Epoch 7/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6991 - acc: 0.7666 - val_loss: 0.5532 - val_acc: 0.7789\n",
            "Epoch 8/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6968 - acc: 0.7671 - val_loss: 0.5461 - val_acc: 0.7752\n",
            "Epoch 9/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6952 - acc: 0.7668 - val_loss: 0.5247 - val_acc: 0.7984\n",
            "Epoch 10/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6938 - acc: 0.7670 - val_loss: 0.5288 - val_acc: 0.7958\n",
            "Epoch 11/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6926 - acc: 0.7675 - val_loss: 0.5260 - val_acc: 0.7809\n",
            "Epoch 12/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6914 - acc: 0.7677 - val_loss: 0.5263 - val_acc: 0.7932\n",
            "Epoch 13/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6907 - acc: 0.7672 - val_loss: 0.5548 - val_acc: 0.7695\n",
            "Epoch 14/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6894 - acc: 0.7678 - val_loss: 0.5486 - val_acc: 0.7713\n",
            "Epoch 15/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6885 - acc: 0.7679 - val_loss: 0.5344 - val_acc: 0.7737\n",
            "Epoch 16/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6878 - acc: 0.7679 - val_loss: 0.5632 - val_acc: 0.7581\n",
            "Epoch 17/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6868 - acc: 0.7681 - val_loss: 0.5577 - val_acc: 0.7570\n",
            "Epoch 18/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6861 - acc: 0.7683 - val_loss: 0.5448 - val_acc: 0.7714\n",
            "Epoch 19/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6856 - acc: 0.7682 - val_loss: 0.5288 - val_acc: 0.7893\n",
            "Epoch 20/20\n",
            "3755947/3755947 [==============================] - 72s 19us/step - loss: 0.6850 - acc: 0.7683 - val_loss: 0.5322 - val_acc: 0.7840\n",
            "Trained in 24 minutes, 01 seconds\n",
            "Copying file:///content/Mon_11_25_johnson2_W_weight_double_model_0_gender_1574728021.4809978.h5 [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/4.1 MiB.                                      \n",
            "Proportion of predictions for W class: 0.15697333819355846\n",
            "gender ROC_AUC: 0.6789110370849715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "gender precision: 0.2990815035972715\n",
            "gender recall: 0.30707636538362115\n",
            "gender precision-recall AUC: 0.3029141514518727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3739617 samples, validate on 2150792 samples\n",
            "Epoch 1/20\n",
            "2030000/3739617 [===============>..............] - ETA: 29s - loss: 0.8941 - acc: 0.5361Copying file:///content/Mon_11_25_johnson2_W_weight_double_model_0_party_1574728021.4809978.h5 [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  4.1 MiB/  4.1 MiB]                                                \n",
            "Operation completed over 1 objects/4.1 MiB.                                      \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4743f8f90163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gsutil cp /content/{party_model_path} gs://fb-congressional-data/models/{party_model_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m   \u001b[0mpreds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m   \u001b[0mdev_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probs2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0mdev_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preds2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_to_party_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lToXFzF6PbK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "648f2ff5-ec72-4ed4-f2a5-95e7f2383067"
      },
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "dev_df.probs.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count   2150792.000\n",
              "mean          0.369\n",
              "std           0.170\n",
              "min           0.000\n",
              "25%           0.278\n",
              "50%           0.371\n",
              "75%           0.459\n",
              "max           1.000\n",
              "Name: probs, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLsmpnYQPcn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}